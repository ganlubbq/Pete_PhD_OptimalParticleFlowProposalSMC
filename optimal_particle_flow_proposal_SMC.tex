\documentclass{article}

\usepackage[pdftex]{graphicx}
\usepackage[caption=false,font=footnotesize]{subfig}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{IEEEtrantools}

\usepackage{algorithm}
\usepackage{algorithmic}

%\usepackage{harvard}

\usepackage{color}

\graphicspath{{./}}

\newenvironment{meta}[0]{\color{red} \em}{}

\title{Optimal Proposals Using Particle Flow for SMC Samplers}
\author{Pete Bunch}
\date{January 2012}

\begin{document}

\maketitle

\section{Introduction}

A particle filter is an algorithm used for sequential estimation of a filtering distribution in a state-space model. For a comprehensive introduction, see for example \cite{Cappe2007,Doucet2009}. Here we consider the use of particle filters for inference with a standard discrete-time hidden Markov model (HMM).

The particle filter advances a set of samples through time, drawn approximately from the filtering distribution. This is achieved by sampling at each time step from an importance distribution and then weighting the particles to account for the discrepancy between target and importance densities.

One of the principal difficulties when designing a particle filter is the selection of the importance distribution. The easiest choice is to sample from the transition density, which leads to a simplification in the weight formula. The resulting algorithm is the ``bootstrap filter'' of \cite{Gordon1993}. In many cases, such bootstrap proposals result in poor filter performance due to a mismatch in the areas of high probability in the transition and observation densities.

Amongst others, \cite{Doucet2000a} demonstrated that the ideal choice of importance density is the conditional posterior given both the previous state and the new observation, dubbed the ``optimal importance distribution''. In all but a few cases, this cannot be calculated analytically (and in those few, a particle filter would be unnecessary anyway). A popular solution is to use an extended (EKF) or unscented (UKF) Kalman filter to select a Gaussian importance distribution. However, such schemes can fail when the model is highly nonlinear or non-Gaussian, as the approximation is poor.

In this paper, we consider a new scheme for proposing samples from the optimal importance distribution. This relies on uniting two recent advances in particle filter research. The first is the concept of an augmented target distribution, introduced in the context of sequential Monte Carlo (SMC) samplers in \cite{DelMoral2006}. By extending the space spanned by the target distribution using an artificial extension, an intractable weight calculations can be avoided. The second idea we use is that of particle flow or transport, developed independently by \cite{Daum2008,Daum2011d} and \cite{Reich2011}. In these papers, schemes are developed for deterministically moving particles according to a homotopy or transport map such that they represent the required posterior distribution.

While powerful, particle flow methods are limited to a certain class of state spaces. (The state must be a vector of continuous variables with the filtering distribution nowhere vanishing in $\mathbb{R}^d$.) Here we modify them for sampling particles from the optimal importance density, for use with mixed continuous-discrete states and for continuous states with known boundaries.



\section{Particle Filter Basics}

We consider a standard discrete-time HMM,
%
\begin{IEEEeqnarray}{rCl}
 x_t & \sim & p(x_t | x_{t-1}) \label{eq:td} \\
 y_t & \sim & p(y_t | x_{t-1}) \label{eq:od} \\
 x_0 & \sim & p(x_0 )          \label{eq:pd}      ,
\end{IEEEeqnarray}
%
where $x_t$ is the time-evolving hidden state of a system, and $y_t$ is an incomplete, noisy observation. We assume here that the transition \eqref{eq:td}, observation \eqref{eq:od} and prior \eqref{eq:pd} densities may be evaluated and that the prior and transition densities may be sampled. The task of filtering is to estimate the distribution of each state in turn given the observations up to the current time, referred to as the filtering distribution, $p(x_t | y_{1:t})$.

If the model densities are all Gaussian, with the transition density mean only linearly dependent on the previous state and the observation density mean only linearly dependent on the current state, then a recursion for the filtering density is given by the Kalman filter \cite{Grewal2002}. If the dependence is nonlinear then approximations such as the EKF or UKF may be used. However, these are only reliable for weak nonlinearity.

Particle filters may be used even when the model densities are nonlinear and non-Gaussian. The filtering density is represented by a set of weighted particles drawn approximately from it using sequential importance sampling,
%
\begin{IEEEeqnarray}{rCl}
 p(x_t | y_{1:t}) & = & \sum_i w_t^{(i)} \delta_{x_{t}^{(i)}}(x_t)     .
\end{IEEEeqnarray}
%
Particles are generated by first sampling $x_{t-1}^{(i)}$ from the previous time's filtering approximation, and then proposing a new state $x_t^{(i)}$ from an importance density, $q(x_t | x_{t-1}^{(i)}, y_t)$. Finally, an importance weight is assigned to the particle,
%
\begin{IEEEeqnarray}{rCl}
 w_t^{(i)} & = & \frac{ p(y_t | x_t^{(i)}) p(x_t^{(i)} | x_{t-1}^{(i)}) }{ q(x_t | x_{t-1}^{(i)}, y_t) }     .
\end{IEEEeqnarray}

Unlike the EKF and UKF, particle filters are ``exact'', in the sense that as the number of particles tends to infinite, integrals over the density converge to the true value.

The practical performance of the particle filter is determined by the variance of the weights. If this is high, then only a small proportion of the particles (perhaps only one) will be significant, and only these will be taken forward to the next filtering step. Clearly, a lower number of significant particles leads to a poorer representation of the distribution, resulting in an increased estimator variance and propensity for the filter to diverge or ``lose track''. The particle weight variance may be measured using the effective sample size (ESS), defined as,
%
\begin{IEEEeqnarray}{rCl}
 N_{E,t} & = & \frac{ 1 }{ \sum_i w_t^{(i)2} }     ,
\end{IEEEeqnarray}
%
This quantity takes a value between $1$ (bad) and $N_F$ (good), the number of filtering particles.

The simplest choice of importance density is use the transition density,
\begin{IEEEeqnarray}{rCl}
 q(x_t | x_{t-1}^{(i)}, y_t) = p(x_t^{(i)} | x_{t-1}^{(i)})     .
\end{IEEEeqnarray}
%
This results in the ``bootstrap filter'' of \cite{Gordon1993}. Often this is inefficient, especially when the variance of the transition density is greater than that of the observation density. With such a condition, the samples are widely spread over the state space, and only a few fall in the region of high likelihood. This results in a large weight variance and poor filter performance.

It was shown in \cite{Doucet2000a}, and references therein, that the weight variance is minimised by using the conditional posterior as the importance distribution,
%
\begin{IEEEeqnarray}{rCl}
 q(x_t | x_{t-1}^{(i)}, y_t) & = & p(x_t | x_{t-1}^{(i)}, y_t).
\end{IEEEeqnarray}
%
This choice is thus known as the ``optimal importance density'' (OID). It may be sampled from, and the weights calculated in closed form, when the observation density is linearly dependent on the state and both transition and observation densities are Gaussian. (The state need not be linearly dependent on the previous state.) However, for most models this density can be neither calculated, nor efficiently sampled from. Thus, it is common to use the same Gaussian approximations to estimate and sample from the OID as were used in the formulation of the EKF and UKF \cite{Doucet2000a,Merwe2000}. These work well when the OID is unimodal, and the observation nonlinearity is weak, but can otherwise perform worse even than the bootstrap filter.



\section{Extended Target Distributions}

Sometimes it may be possible to sample from an importance distribution but not possible to evaluate its density. For example, consider the following composite case,
%
\begin{IEEEeqnarray}{rCl}
 q(x_t | x_{t-1}, y_t) & = & \int q_{\phi}(x_t | x_{t-1}, y_t, \phi) q(\phi) d\phi     ,
\end{IEEEeqnarray}
%
where the integral has no analytic solution. A particle can be generated by first sampling the parameter $\phi \sim q(\phi)$ and then sampling a state $x_t \sim q_{\phi}(x_t | x_{t-1}, y_t, \phi)$. The value of $\phi$ is then discarded (marginalised). However, evaluation of the importance weight requires a solution to the integral, which does not exist.

The solution to this problem is to introduce the parameter into the target distribution, by using an artificial conditional density \cite{DelMoral2006}. The new target distribution is,
%
\begin{IEEEeqnarray}{rCl}
 p(x_t | y_{1:t}) \rho(\psi | x_t, y_{1:t})     ,
\end{IEEEeqnarray}
%
and the corresponding proposal is,
\begin{IEEEeqnarray}{rCl}
 q(x_t | x_{t-1}, y_t) & = & q_{\phi}(x_t | x_{t-1}, y_t, \phi) q(\phi)     .
\end{IEEEeqnarray}
%
The importance weight now requires nothing more than the evaluation of the various densities --- no integration is needed. Finally, the value of $\phi$ is no longer needed and may be discarded (marginalised). The artificial conditional density is a design parameter; whatever we choose, the marginal state distribution will be $p(x_t | y_{1:t})$. However, our choice will affect the variance of the importance weights. The optimal choice (in the minimum variance sense) is shown in \cite{DelMoral2006}.



\section{Particle Flows}

In a series of papers including \cite{Daum2008,Daum2011d,Daum2012a}, the authors introduce a new method for particle filtering. Similar ideas (but restricted to Gaussian densities) are described in \cite{Reich2011}. The principal behind these filters is to sample the a set of particles from the prior distribution, $p(x_t | y_{1:t-1})$, and then use a deterministic method to move them such that they are then distributed according to the posterior. By considering the continuous introduction of the observation density, a particle ``flow'' is determined. Integrating this flow with standard ordinary differential equation (ODE) solvers provides us with the required deterministic movement. See the aforesaid references for an introduction to particle flow methods.

While ingenious and ground-breaking, these particle flow methods are restricted to a particular class of models. In particular, the filtering distribution must be nowhere vanishing in $\mathbb{R}^d$. (Actually, we believe that regions of zero probability are allowable, provided the particle flow is always parallel to --- or zero at --- the boundaries of these regions.) This means that hard limits on the state space, which often arise as a result of physical constraints, cannot be accommodated. Furthermore, particle flow methods are limited to continuous state spaces. They cannot be used when the state contains indicator or other discrete variables, which are often used to model alternative modes of operation, etc.

To address these limitations, we introduce the idea of using particle flow methods as a proposal mechanism within a standard particle filter. This will allow us to draw particles from the OID for a broad class of nonlinear, non-Gaussian models without resorting to a Gaussian approximation.



\section{Optimal Proposal with Particle Flows}

In this section, we follow the derivations of \cite{Daum2008} but consider sampling the OID rather than the full posterior distribution.

We desire a particle drawn from the optimal importance distribution,
%
\begin{IEEEeqnarray}{rCl}
 p(x_t | x_{t-1}^{(i)}, y_t) & = & \frac{ p(x_t | x_{t-1}^{(i)}) p(y_t | x_t) }{ p(y_t | x_{t-1}^{(i)}) }     .
\end{IEEEeqnarray}
%
To obtain this, we consider the following homotopy between the prior density and the posterior\footnote{Particle index superscripts are omitted for clarity in this derivation},
%
\begin{IEEEeqnarray}{rCl}
 \pi(x_t, \lambda) & \propto & p(x_{t} | x_{t-1}) p(y_t | x_t)^\lambda \nonumber \\
 \log\left( \pi(x_t, \lambda) \right) & = & \log\left( \underbrace{p(x_{t} | x_{t-1})}_{\alpha(x_t)} \right) + \lambda \log\left( \underbrace{p(y_t | x_t)}_{\beta(x_t)} \right) - K(\lambda)     ,
\end{IEEEeqnarray}
%
where $\lambda \in [0,1]$ may be considered as a ``loop of synthetic time'' \cite{Daum2008}. When $\lambda=0$, we have the prior density, and when $\lambda=1$, the posterior. Differentiating this log-homotopy gives us,
%
\begin{IEEEeqnarray}{rCl}
 \frac{\partial}{\partial \lambda} \log\left( \pi(x_t, \lambda) \right) & = & \frac{ 1 }{ \pi(x_t, \lambda) } \frac{\partial \pi}{\partial \lambda} \nonumber \\
  & = & \log\left(\beta(x_t)\right) \label{eq:diff-LH}     ,
\end{IEEEeqnarray}
%
and\footnote{Using $\nabla$ to mean $\nabla_{x_t}$.}
\begin{IEEEeqnarray}{rCl}
 \nabla \log\left( \pi(x_t, \lambda) \right) & = & \frac{ 1 }{ \pi(x_t, \lambda) } \nabla \pi(x_t, \lambda) \label{eq:div-LH}     .
\end{IEEEeqnarray}

The Fokker-Planck equation relates the flow of a particle with the flow of the density for its position. If we assume that the particles move deterministically according to,
%
\begin{IEEEeqnarray}{rCl}
 \frac{dx_t}{d\lambda} & = & f(x_t, \lambda)     ,
\end{IEEEeqnarray}
%
then from Fokker-Planck, \eqref{eq:diff-LH} and \eqref{eq:div-LH}, we have,
%
\begin{IEEEeqnarray}{rCl}
 \frac{\partial \pi}{\partial \lambda} & = & -\nabla \cdot \left[ f(x_t, \lambda) \pi(x_t, \lambda) \right]     \nonumber \\
 \pi(x_t, \lambda) \log\left(\beta(x_t)\right)  & = & -\nabla\cdot f(x_t, \lambda) \pi(x_t, \lambda) - f(x_t, \lambda) \cdot \nabla \pi(x_t, \lambda) \nonumber \\
 \log\left(\beta(x_t)\right) & = & -\nabla\cdot f(x_t, \lambda) - f(x_t, \lambda) \cdot \nabla \log\left( \pi(x_t, \lambda) \right)      .
\end{IEEEeqnarray}
%
where in the last step we have divided through by $\pi$. This requires the density to be nowhere vanishing.

The result is a highly under-determined partial differential equation (PDE), and any solution for $f(x_t, \lambda)$ will result in a flow which transfers the prior particles to new locations which represent the posterior. This is achieved by numerically integrating $f(x_t, \lambda)$ along the particle trajectory over the range $\lambda \in [0, 1]$. The remaining task, then, is to find efficient solutions to the PDE. A number of these are detailed in \cite{Daum2008,Daum2011d,Daum2012a} and the references therein. In the following sections, we make use of the following solutions.

\subsection{Gaussian densities}

If the transition and observation densities are Gaussian, and the observation function is 


\section{Numerical Illustrations}



\section{Conclusions}





\section{The Situation}

Consider a particle filter for estimating $p(x_{1:t} | y_{1:t})$. Lets say that the transition density, $p(x_t | x_{t-1})$, is easily sampled and that both the transition density and the likelihood, $p(y_t | x_t)$, can be evaluated and differentiated. The optimal proposal density is $p(x_t | x_{1:t-1}, y_t)$. In our example, This, in general, cannot be sampled from, nor easily approximated, and may well be multimodal.

If we simply use the transition density as the importance density (i.e. a bootstrap filter) then we will need many particles to get a good approximation.



\section{Particle Flow}

Fred Daum's particle flow filter works on the following principle. First conduct a set of bootstrap proposals to generate particles from $p(x_{1:t} | y_{1:t-1})$. Now define a ``log-homotopy'' from $p(x_{1:t} | y_{1:t-1})$ to $p(x_{1:t} | y_{1:t})$ as follows,
%
\begin{IEEEeqnarray}{rCl}
 \log\left( p(x_t, \lambda) \right) & = & \log\left( \underbrace{p(x_{t} | y_{1:t-1})}_{g(x_t)} \right) + \lambda \log\left( \underbrace{p(y_t | x_t)}_{h(x_t)} \right)     .
\end{IEEEeqnarray}

When $\lambda=0$, $p(x_t, \lambda)$ is equal to the prior density, and when $\lambda=1$, it's equal to the posterior. Now we just use the Fokker-Planck equation ``backwards'' to work out the flow of particles corresponding to this flow of density. This requires the solution to an under-determined PDE, which will often require numerical methods, to discover $f(x_t, \lambda)$ and then the solution to the ODE $f(x_t, \lambda)=\frac{dx_t}{d\lambda}$.

The things I don't like about this are:
\begin{itemize}
  \item A lot of numerical approximations are required to solve the PDE. The one I am most suspicious of is that required to evaluate $g(x)$ at arbitrary points. This can be done using a particle approximation, but this yields an $\mathcal{O}(N^2)$ algorithm. Fred avoids this by using only a small subset of ``approximate nearest neighbour'' particles. I am suspicious of this.
  \item I think there's a problem with multimodal posteriors when one mode is eliminated. How do we remove the particles at this mode. They suddenly have to make a huge jump to the other modes. If they all go to the nearest mode, then this will bias the posterior. We \emph{need} resampling to allow us to ``kill'' particles.
  \item Fred's derivations all require $p(x_t,\lambda)$ to be nowhere vanishing. This is not the case when the domain of $x_t$ is limited, for example a state variable which is strictly positive (e.g. a variance). If there are zeros in the likelihood, we need to be able to kill particles which fall in that region, or otherwise deal with them. If there are zeros in the prior, then we need the boundary condition that $f(x_t, \lambda)$ be parallel to the boundary, so that particles cannot move into the zero-probability region.
  \item There's no way to deal with mixed states, when we want to estimate discrete and continuous variables in parallel.
\end{itemize}



\section{Optimal Proposals}

Instead of sampling $p(x_t | y_{1:t})$ using the homotopy, we can sample the optimal proposal density, $p(x_t | x_{t-1}, y_t)$. This solves the first problem in the list above, because we now have $g(x_t)=p(x_t|x_{t-1})$ in our homotopy, which can be both evaluated and probably differentiated analytically.

A further corollary of this is that our particles will now have a weight again, so we will need to reintroduce resampling. This solves the second problem, although it does reintroduce a bottleneck.

The weight evaluation is problematic, since the particle weights ought to be $w_t = p(y_t | x_{t-1})$, which cannot be evaluated. We solve this by using an SMC sampler which jointly targets the prior and posterior positions of the particles (i.e. before and after the homotopy is applied). The proposal is thus,
%
\begin{IEEEeqnarray}{c}
 p(x_{1:t-1} | y_{1:t-1}) p(x_t^* | x_{t-1}) \delta_{F(x_t^*)}(x_t)     ,
\end{IEEEeqnarray}
%
where $x_t^*$ is the prior state of the particle and $x_t$ the posterior, and $F(x)$ describes the effect of the homotopy. We use the augmented target distribution,
%
\begin{IEEEeqnarray}{rCl}
 p(x_{1:t} | y_{1:t}) \delta_{F^{-1}(x_t)}(x_t^*)     .
\end{IEEEeqnarray}
%
This leads to an unnormalised weight of,
%
\begin{IEEEeqnarray}{rCl}
 w_t & = & \frac{ p(y_t|x_t)p(x_t|x_{t-1}) }{ p(x_t^* | x_{t-1}) }     .
\end{IEEEeqnarray}

For the above scheme to be valid, we need the support of the proposal to contain that of the target. This is only the case if $F$ is bijective (I think), necessary conditions for which are that $f(x_t, \lambda)$ be smooth and the boundary condition $f(x_t, \lambda)$ parallel to the boundary of the region $g(x_t)=0$.



\bibliographystyle{plain}
\bibliography{D:/pb404/Dropbox/PhD/OTbib}

\end{document} 