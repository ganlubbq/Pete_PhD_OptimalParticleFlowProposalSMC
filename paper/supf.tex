\documentclass{statsoc}

%%% Packages %%%

% Graphics
\usepackage{graphicx}
\usepackage[caption=false,font=footnotesize]{subfig}

% Formatting
\usepackage{color}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{bbm}
\usepackage[T1]{fontenc}

% Environments
\usepackage{IEEEtrantools}
\usepackage{algorithm}
\usepackage{algorithmic}

% References
\usepackage{natbib}



%%% Macros %%%
\input{supf_macros}



%%% Environments %%%
\newenvironment{meta}[0]{\color{red} \em}{}
\newtheorem{lemma}{Lemma}



%%% Titles and stuff %%%
\title[Smooth Update Particle Filter]{The Smooth Update Particle Filter: Better Approximations to the Optimal Importance Density}
\author[Bunch {\it et al.}]{Pete Bunch}
\address{Cambridge University Engineering Department,
Cambridge,
UK.}
\email{pb404@cam.ac.uk}



%%% DOCUMENT %%%

\begin{document}



\begin{abstract}
Abstract here.
\end{abstract}



\keywords{particle filter, tempering, sequential Monte Carlo}



\section{Introduction}

A particle filter is an algorithm used for sequential estimation of a filtering distribution for a state-space model. For a comprehensive introduction, see for example \citep{Cappe2007,Doucet2009}. In this paper we consider the use of particle filters for inference with a standard discrete-time hidden Markov model (HMM).

The particle filter advances a set of samples through time, drawn approximately from the filtering distribution. This is achieved by sampling at each time step from an importance distribution and then weighting the particles to account for the discrepancy between target and importance distributions. Particle filters have attractive asymptotic properties: as the number of particles is increased, certain estimates are guaranteed to converge to their true values. % Resampling steps are used to control the variance of the importance weights, and prevent a single particle from dominating the set.

One of the principal difficulties when designing a particle filter is the selection of the importance distribution. The simplest choice is often to sample from the transition model, resulting in the ``bootstrap filter'' of \citep{Gordon1993}. In many cases, such bootstrap proposals result in poor filter performance due to a mismatch in the areas of high probability between the transition and observation distributions.

Amongst others, \citet{Doucet2000a} demonstrated that the ideal choice of importance distribution for each particle is the conditional posterior given both the previous state and the new observation, dubbed the ``optimal importance distribution'' (OID). In all but a few cases, this cannot be calculated analytically. When the state variables are continuous, a popular solution is to use an extended (EKF) or unscented (UKF) Kalman filter to select a Gaussian importance density for each particle. However, such schemes can fail when the model is highly nonlinear or non-Gaussian, as the approximation is poor.

The effect of using a bad importance distribution (i.e. one which is not ``close'' to the OID) is that the variance of the importance weights is high, resulting in a degeneracy of the filter. In the worst cases, there may be no particles at all proposed in regions of high posterior probability, causing the filter to fail entirely. This problem is especially pronounced when the dimensionality of the state space is high --- there is simply more space for the particles to cover.

Numerous additions and modifications to the basic particle filter have been proposed. With some models it may be possible to marginalise a subset of the state variables --- a process known as ``Rao-Blackwellisation'' --- and hence to reduce the dimensionality of the samples in the particle filter \citep{Casella1996,Doucet2000}.

A more generally applicable enhancement is to insert Markov chain Monte Carlo (MCMC) steps to rejuvenate a degenerate set of particles, a method named ``resample-move'' by \citet{Gilks2001}. However, for this to work effectively and efficiently, it is necessary that the preceding importance sampling stage manages to place at least $1$ particle in each interesting region of the state space (i.e. where the posterior probability is high). In addition, an MCMC stage introduces new algorithm parameters which need to be tuned for effective operation: e.g. the number of MCMC steps per particle, and the proposal distribution.

\subsection{Annealing and Particle Flows}

Another way in which degeneracy may be mitigated is by introducing the effect of each observation gradually, so that particles may be progressively drawn towards peaks in the likelihood. This can be achieved by using a discrete set of bridging distributions which transition smoothly between the prior and posterior. Such ``annealing'' schemes have been suggested by, amongst others, \citet{Neal2001} (using MCMC) and \citet{DelMoral2006} (using Sequential Monte Carlo (SMC) samplers) for static inference problems, and by \citet{Godsill2001b} for a particle filter.

It is possible to take the idea of bridging distributions to a limit and define a continuous sequence of distributions between the prior and the posterior. This device was used by \citet{Gelman1998} for the related task of simulating normalising constants. More recently, particle filters have appeared which exploit the same principle, including the ``particle flow'' methods described in series of papers including \citep{Daum2008,Daum2011d}, and the ``optimal transport'' methods of \cite{Reich2011,Reich2012a}.

In a particle flow filter, a sequence of densities is defined at each time step between the predictive and filtering densities, parameterised by a ``pseudo-time'' variable which increases from $0$ to $1$. Each frame of the filtering algorithm begins with the sampling of a set of particles from the predictive density. The particles are then imbued with some appropriate dynamics such that they are always distributed according to the density sequence as they advance through pseudo-time, and thus follow the required filtering density when the interval of pseudo-time ends. The dynamics may be deterministic \citep{Daum2008}, or stochastic \citep{Daum2013,Reich2011}. In either case, correct drift and diffusion terms may be derived using the Fokker-Planck equation, which relates the evolution of densities (which is specified) to the corresponding flow of particles.

A significant advantage of particle flow filters is that particles are equally weighted throughout. Consequently, they do not require any resampling and are easily parallelised. However, while extremely elegant, they suffer from a number of drawbacks:
\begin{enumerate}
  \item There is only one model for which the particle dynamics can be derived and integrated analytically: the linear Gaussian case, for which there already exists the optimal and far more efficient Kalman filter. For every other model, it is necessary to make either numerical or functional approximations in order to evaluate the particle flow, besides which this flow must then be numerically integrated. For example, it seems generally to be required that it be possible to evaluate the filtering density at arbitrary points. This is addressed in \citep{Daum2012} by using a Monte Carlo approximation, and in \citep{Reich2012a} by using a Gaussian-mixture approximation. The problem with these approximations is that they alter the distribution of the particles such that it is no longer exactly equal to the filtering distribution, and the resulting errors thus introduced are not easily quantified. Hence, these particle flow methods do not have the appealing asymptotic consistency of an ordinary particle filter.
  \item Particle flow algorithms are restricted to certain classes of state space. Only continuous states can be handled, and for these the density must be nowhere vanishing. Bounds on the state, such as are frequently available in physical problems, cannot be handled easily.
  \item A by-product of standard particle filtering is that, for no extra computational cost, an estimate of the smoothing distribution may be formed by simply tracing the ancestry of each particle. This is sometimes useful directly, but more often as a starting point for more sophisticated smoothing algorithms \citep{Godsill2004,Bunch2012} or parameter estimation schemes \citep{Andrieu2010}. Particle flow filters do not retain this property --- only a filtering estimate is produced.
\end{enumerate}

\subsection{Smooth Updates}

In this paper, we attempt to reconcile the elegant and powerful techniques of particle flows with the standard framework for particle filtering. This is achieved by using a particle flow as a mechanism for sampling from an approximation to the OID, rather than attempting to sample directly from the filtering distribution, and by exploiting the analytic results available for a particular class of models. The resulting algorithm, which we dub the smooth update particle filter (SUPF), is free from the drawbacks of existing particle flow filters discussed above, but also loses the property of equally weighted particles.

The SUPF resembles an SMC-based annealing algorithm of the form described in \citep{DelMoral2006}, but equipped with near-optimal importance densities for each step. Furthermore, there exists a special case in which the procedure ceases to use sampling at all, but moves the particles deterministically. Since the algorithm relies on the use of gradient and curvature information from the target density, there are also connections with adaptive MCMC methods, such as those of \citep{Girolami2011}.

Having covered some particle filter basics in section , we introduce a framework for new algorithm in section . In section , an optimal solution is derived for the partially nonlinear Gaussian case, and in section , this is employed as a tool for implementing quasi-optimal solutions for other models. Numerical illustrations are presented in section . {\meta Update this.}



\section{Particle Filtering}

\subsection{Basics}

We consider a standard discrete-time HMM in which the transition, observation and prior models have closed-form densities,
%
\begin{IEEEeqnarray}{rCl}
 \ls{\rt} & \sim & p(\ls{\rt} | \ls{\rt-1}) \label{eq:td} \\
 \ob{\rt} & \sim & p(\ob{\rt} | \ls{\rt})   \label{eq:od} \\
 \ls{1} & \sim & p(\ls{1})                  \label{eq:pd}      ,
\end{IEEEeqnarray}
%
where the random variable $\ls{\rt}$ is the hidden state of a system at time $\rt$, and $\ob{\rt}$ is an incomplete, noisy observation. We assume here that the transition, observation and prior densities may be evaluated and that the prior and transition densities may be sampled. A particle filter is used to estimate recursively distributions over the path of the state variables, $\ls{1:\rt}=\{\ls{1}, \dots, \ls{\rt}\}$. Densities are approximated by a sum of weighted probability masses located at a discrete set of states,
%
\begin{IEEEeqnarray}{rCl}
 p(\ls{1:\rt} | \ob{1:k}) & = & \sum_i \npw{\rt}\pss{i} \delta_{\ls{1:\rt}\pss{i}}(\ls{1:\rt})     ,
\end{IEEEeqnarray}
%
where $\delta_{\ls{1:\rt}\pss{i}}(\ls{1:\rt})$ denotes a unit probability mass at the point $\ls{1:\rt}\pss{i}$.

The particle filter recursion may be separated into two stages --- prediction and update --- which produce approximations to the predictive, $p(\ls{1:\rt} | \ob{1:\rt-1})$, and filtering, $p(\ls{1:\rt} | \ob{1:\rt})$, densities respectively. (Note, these terms more conventionally refer to the density of the latest state only, rather than the entire path.)

At time $\rt$, the prediction stage begins with selection (or ``resampling'') of a parent from amongst the $\rt-1$ particles; an index, $\anc{j}$, is chosen with probability (or ``auxiliary weight'') $\naw{t-1}\pss{j}$. This is equivalent to sampling from a density $\impden(\ls{1:\rt-1} | \ob{1:\rt-1})$, where,
%
\begin{IEEEeqnarray}{rCl}
 \impden(\ls{1:\rt-1}\pss{i} | \ob{1:\rt-1}) & \propto & \frac{ \naw{\rt-1}\pss{i} }{ \npw{\rt-1}\pss{i} } p(\ls{1:\rt-1}\pss{i} | \ob{1:\rt-1}) \nonumber      .
\end{IEEEeqnarray}

Next, a new state $\ls{\rt}\pss{j}$ is sampled from an importance density, $\impden(\ls{\rt} | \ls{\rt-1}\pss{\anc{j}}, \ob{\rt})$, and concatenated to the parent path to form the new particle,
%
\begin{IEEEeqnarray}{rCl}
 \ls{1:\rt}\pss{j} \leftarrow \left\{ \ls{1:\rt-1}\pss{\anc{j}},  \ls{\rt}\pss{j} \right\}     .
\end{IEEEeqnarray}
%
Finally, an importance weight is assigned to the particle to account for the discrepancy between importance and target distributions,
%
\begin{IEEEeqnarray}{rCl}
 \predpw{\rt}\pss{j} & = & \frac{ p(\ls{1:\rt}\pss{j} | \ob{1:\rt-1}) }{ \impden(\ls{1:\rt-1}\pss{\anc{j}} | \ob{1:\rt-1}) \impden(\ls{\rt}\pss{j} | \ls{\rt-1}\pss{\anc{j}}, \ob{\rt}) } \nonumber \\
 & \propto & \frac{\npw{\rt-1}\pss{j}}{\naw{t-1}\pss{\anc{j}}} \times \frac{ p(\ls{\rt}\pss{j} | \ls{\rt-1}\pss{\anc{j}}) }{ \impden(\ls{\rt}\pss{j} | \ls{\rt-1}\pss{\anc{j}}, \ob{\rt}) }     .
\end{IEEEeqnarray}

In the update stage, the same set of particles is used to approximate the filtering distribution. These are distributed according to $\impden(\ls{1:\rt} | \ob{1:\rt})$, where,
%
\begin{IEEEeqnarray}{rCl}
 p(\ls{1:\rt}\pss{j} | \ob{1:\rt-1}) & \propto & \predpw{\rt}\pss{j} \impden(\ls{1:\rt}\pss{j} | \ob{1:\rt}) \nonumber      .
\end{IEEEeqnarray}
%
A new importance weight is required to account for the discrepancy,
%
\begin{IEEEeqnarray}{rCl}
 \pw{\rt}\pss{j} & =       & \frac{ p(\ls{1:\rt}\pss{j} | \ob{1:\rt}) }{ \impden(\ls{1:\rt}\pss{j} | \ob{1:\rt}) } \nonumber \\
                 & \propto & \predpw{\rt}\pss{j} \times p(\ob{\rt} | \ls{\rt}\pss{j} )      .
\end{IEEEeqnarray}
%
Finally, the weights are normalised,
%
\begin{IEEEeqnarray}{rCl}
 \npw{\rt} & = & \frac{ \pw{\rt}\pss{j} }{ \sum_i \pw{\rt}\pss{i} }      .
\end{IEEEeqnarray}

If the two steps are considered together, then the combined weight update is,
%
\begin{IEEEeqnarray}{rCl}
 \pw{\rt}\pss{j} & = & \frac{ p(\ls{1:\rt}\pss{j} | \ob{1:\rt}) }{ \impden(\ls{1:\rt-1}\pss{\anc{j}} | \ob{1:\rt-1}) \impden(\ls{\rt}\pss{j} | \ls{\rt-1}\pss{\anc{j}}, \ob{\rt}) } \nonumber \\
 & \propto & \frac{\npw{\rt-1}\pss{j}}{\naw{t-1}\pss{\anc{j}}} \times \frac{ p(\ob{\rt} | \ls{\rt}\pss{j}) p(\ls{\rt}\pss{j} | \ls{\rt-1}\pss{\anc{j}}) }{ \impden(\ls{\rt}\pss{j} | \ls{\rt-1}\pss{\anc{j}}, \ob{\rt}) }     .
\end{IEEEeqnarray}

Particle filters have the highly desirable property of asymptotic consistency; as the number of particles tends to infinite, integrals of bounded functions over the filtering density converge to the true value.

The practical performance of the particle filter is determined by the variance of the weights. If this is high, then only a small proportion of the particles (perhaps only one) will be significant, and only these will be taken forward to the next filtering step. Clearly, a lower number of significant particles leads to a poorer representation of the distribution, resulting in an increased estimator variance and propensity for the filter to diverge completely from the true value. The particle weight variance may be measured using the effective sample size (ESS), defined as,
%
\begin{IEEEeqnarray}{rCl}
 \ess{\rt} & = & \frac{ 1 }{ \sum_i \npw{\rt}\pss[2]{i} }     ,
\end{IEEEeqnarray}
%
Intuitively, this is the number of particles which would be present in an equivalent set comprised of independent, unweighted samples. It takes a value between $1$ (which is bad) and the number of filtering particles, $\numpart$ (which is good).

\subsection{Design Considerations}

The remaining considerations in the design of a particle filter are the choices of the auxiliary weights, $\naw{\rt-1}\pss{j}$, and the importance density, $\impden(\ls{\rt} | \ls{\rt-1},\ob{\rt})$. The options for particle selection are:
\begin{enumerate}
  \item No resampling: Use every particle from the $t-1$ set exactly once. This is achieved by setting $\anc{j}=j$ and corresponds to using $\naw{\rt-1}\pss{j}=\frac{1}{\numpart}$. This uses the least computation and introduces no Monte Carlo error. However, if used exclusively, it will allow the weight variance to accumulate over time and the ESS is guaranteed to fall to $1$.
  \item Standard resampling: Use $\naw{\rt-1}\pss{j}=\npw{\rt-1}\pss{j}$ and sample $\{\anc{i}\}$ using multinomial or systematic resampling \citep{Hol2006}. This prevents the accumulation of weight variance at the cost of some additional Monte Carlo error. It also introduces dependence between the particles.
  \item Auxiliary resampling: Set $\naw{\rt-1}\pss{j}$ so as to minimise the variance of the $\npw{\rt}\pss{j}$ \citep{Pitt1999}. In combination with the optimal importance density, this leads to an equally weighted set of particles. However, this requires the calculation of an integral over the state space which is generally intractable, and approximations of which can lead to worse performance than the simpler options. Therefore, it is not considered here.
\end{enumerate}

Various choices also exist for importance density. The simplest is to use the transition density,
%
\begin{IEEEeqnarray}{rCl}
 \impden(\ls{\rt} | \ls{\rt-1}\pss{\anc{j}}, \ob{\rt}) = p(\ls{\rt} | \ls{\rt-1}\pss{\anc{j}})     .
\end{IEEEeqnarray}
%
This results in the ``bootstrap filter'' of \cite{Gordon1993}. It is only requires that sampling be possible from the transition model, and not that the transition density be calculable. The weight formula simplifies to,
%
\begin{IEEEeqnarray}{rCl}
 \pw{\rt}\pss{j} & \propto & \frac{\npw{\rt-1}\pss{j}}{\naw{\rt-1}\pss{j}} \times p(\ob{\rt} | \ls{\rt}\pss{j}) \label{eq:weight_update_bootstrap}      .
\end{IEEEeqnarray}
%
Furthermore, in combination with standard resampling, the weight associated with the prediction stage is a constant; it is the update stage which is problematic.

Often the bootstrap filter is inefficient, especially when the variance of the transition density is greater than that of the observation density. In this situation, the samples are widely spread over the state space, and only a few fall in the region of high likelihood. This results in a high weight variance, low ESS and poor filter performance.

It was shown in \citep{Doucet2000a}, and references therein, that the weight variance is minimised by using the conditional posterior as the importance distribution,
%
\begin{IEEEeqnarray}{rCl}
 \impden(\ls{\rt} | \ls{\rt-1}\pss{\anc{j}}, \ob{\rt}) & = & p(\ls{\rt} | \ls{\rt-1}\pss{\anc{j}}, \ob{\rt})      ,
\end{IEEEeqnarray}
%
resulting in the following weight formula,
%
\begin{IEEEeqnarray}{rCl}
 \pw{\rt}\pss{j} & \propto & \frac{\npw{\rt-1}\pss{j}}{\naw{\rt-1}\pss{j}} \times p(\ob{\rt} | \ls{\rt-1}\pss{\anc{j}}) \nonumber \\
           & \propto & \frac{\npw{\rt-1}\pss{j}}{\naw{\rt-1}\pss{j}} \times \int p(\ob{\rt} | \ls{\rt}) p(\ls{\rt} | \ls{\rt-1}\pss{\anc{j}}) d\ls{\rt}      .
\end{IEEEeqnarray}
%
This choice is thus known as the ``optimal importance density'' (OID). It may be sampled from, and the weights calculated in closed form, when the observation density is linearly dependent on the state and both transition and observation densities are Gaussian. (The state need not be linearly dependent on the previous state.) However, for most models this density can be neither calculated, nor efficiently sampled from. Thus, it is common to use the same Gaussian approximations to estimate and sample from the OID as were used in the formulation of the EKF and UKF \citep{Doucet2000a,Merwe2000}. These work well when the OID is unimodal, and the observation nonlinearity is weak, but can otherwise perform worse even than the bootstrap filter.



\section{A Framework for the Smooth Update}

The SUPF uses the same prediction step as a bootstrap filter, starting with particle selection and then proposing a new state from the transition density. The novelty lies in the update step.

First, as in \citep{Daum2011d}, a variable $\pt \in [0,1]$ is introduced. Intuitively, this is a stretch of ``pseudo-time'' between the predictive and filtering densities, allowing the effect of the observation to be introduced gradually. Define $\ls{\rt,\pt}$ as the state at time $\rt$ and pseudo-time $\pt$.

Now define a continuous sequence of target densities,
%
\begin{IEEEeqnarray}{rCl}
 \augfiltden{\rt,\pt}(\ls{1:\rt-1}, \ls{\rt,\pt}) & = & \frac{ p(\ob{\rt} | \ls{\rt,\pt})^{\pt} p(\ls{\rt,\pt} | \ls{\rt-1}) p(\ls{1:\rt-1}|\ob{1:\rt-1}) }{ \augfiltnorm{\pt} } \nonumber \\
 \augfiltnorm{\pt} & = & \int p(\ob{\rt} | \ls{})^{\pt} p(\ls{} | \ob{1:\rt-1}) d\ls{}      .
\end{IEEEeqnarray}
%
This is equal to the predictive density when $\pt=0$ and the desired filtering density when $\lambda=1$. Rather than using the same particles for the filtering density as the predictive density, we allow them to move around as we progress incrementally through pseudo-time, targeting $\augfiltden{\rt,\pt}$ at each point with standard SMC methods.

\subsection{The Optimal Particle Flow}

{\meta SORT OUT PARTICLE SUPERCRIPTS AND TIME SUBSCRIPTS.}

Within the SMC framework, the task is now to move the particles in an optimal manner so as to minimise the weight variance. We achieve this by considering the family of optimal importance densities corresponding to $\augfiltden{\rt,\pt}$. For the $(j)$th particle, this is defined by,
%
\begin{IEEEeqnarray}{rCl}
 \oiden{\rt,\pt}(\ls{\rt,\pt} | \ls{\rt-1}\pss{\anc{j}}) & = & \frac{ p(\ob{\rt} | \ls{\rt,\pt})^{\pt} p(\ls{\rt,\pt} | \ls{\rt-1}\pss{\anc{j}}) }{ \oinorm{\pt}(\ls{\rt-1}\pss{\anc{j}}) } \nonumber \\
 \oinorm{\pt}(\ls{\rt-1}\pss{\anc{j}}) & = & \int p(\ob{\rt} | \ls{\rt,\pt})^{\pt} p(\ls{\rt,\pt} | \ls{\rt-1}\pss{\anc{j}}) d\ls{\rt,\pt}      .
\end{IEEEeqnarray}
%
Hence, $\oiden{\rt,0}$ is the transition density and $\oiden{\rt,1}$ the OID for a standard particle filter.

Suppose that as pseudo-time advances from $0$ to $1$, particles are moved according to a stochastic differential equation (time subscripts $\rt$ omitted for clarity),
%
\begin{IEEEeqnarray}{rCl}
 d\ls{\pt}\pss{j} & = & \flowdrift{\pt}\pss{j}(\ls{\pt}\pss{j}) d\pt + \flowdiffuse{\pt}\pss{j} d\flowbm{\pt}\pss{j} \label{eq:flow}     ,
\end{IEEEeqnarray}
%
where $\flowbm{\pt}\pss{j}$ is a Brownian motion. The more general case in which $\flowdiffuse{\pt}$ depends on $\ls{\pt}$ has not been investigated.

An optimal particle flow is defined as a choice of $\flowdrift{\pt}\pss{j}$ and $\flowdiffuse{\pt}\pss{j}$ such that each particle, $\ls{\pt}\pss{j}$, is distributed according to $\oiden{\rt,\pt}(\ls{\rt,\pt} | \ls{\rt-1}\pss{\anc{j}})$, since this results in a sample from the OID at the end of the pseudo-time interval.

The interaction between particle motion and evolution of densities is governed by the Fokker-Planck equation, consideration of which leads us to the following lemma.
%
\begin{lemma}\label{lem:optimal_flow_governing_eq}
Optimal choices of $\flowdrift{\pt}\pss{j}$ and $\flowdiffuse{\pt}\pss{j}$ are governed by the following partial differential equation,
%
\begin{IEEEeqnarray}{rCl}
\log\left(\flowod(\ls{\pt})\right) - \expect{\oiden{\pt}}\left[ \log\left(\flowod(\ls{\pt})\right) \right] & = & -\nabla\cdot \flowdrift{\pt}(\ls{\pt}) - \flowdrift{\pt}(\ls{\pt}) \cdot \nabla \log\left( \oiden{\pt}(\ls{\pt}) \right) \nonumber \\
 &   & \qquad + \: \frac{1}{\oiden{\pt}(\ls{\pt})} \nabla \cdot \left[ \flowcov{\pt} \nabla \oiden{\pt}(\ls{\pt}) \right] \label{eq:optimal_flow_PDE}      ,
\end{IEEEeqnarray}
%
where
%
\begin{IEEEeqnarray}{rCl}
 \flowod(\ls{}) & = & p(\ob{\rt}|\ls{}) \nonumber \\
 \flowcov{\pt} & = & \frac{1}{2} \flowdiffuse{\pt} \flowdiffuse{\pt}^T \nonumber      .
\end{IEEEeqnarray}
%
For proof, see Appendix \ref{app:optimal_flow_governing_eq}.
\end{lemma}

Once the optimal flow has been determined, it can integrated in order to establish an optimal choice for the importance density needed to advance the particle filter over an interval of pseudo time.

Note that although this provides a route for selecting an optimal flow, the results in the following section are applicable for any choice of $\flowdrift{\pt}\pss{j}$ and $\flowdiffuse{\pt}\pss{j}$. Clearly, it will not often be possible to derive an analytic expression for the optimal flow. However, an approximately-optimal flow may yield better filter performance than simply approximating the OID directly, for example with a Gaussian.

\subsection{Importance Densities and Weight Updates}

Beginning with particle $(j)$, with state $\ls{\rt,\pt_0}\pss{j}$ and weight $\pw{\rt,\pt_0}\pss{i}$, which is distributed according to $\augfiltden{\rt,\pt_0}$, consider the change between $\pt_0$ and a later pseudo-time $\pt_1$. For a chosen flow, how should the new state $\ls{\rt,\pt_1}\pss{j}$ be generated and the new weight $\pw{\rt,\pt_1}\pss{i}$ calculated such that the particle is distributed according to $\augfiltden{\rt,\pt_1}$?

We examine two cases separately; the first where $\flowdiffuse{\pt}\pss{j}=0$, and the particle is moved entirely deterministically, and second case where $\flowdiffuse{\pt}\pss{j}\ne0$ and the particle moves stochastically.

\subsubsection{Deterministic Flows}

When $\flowdiffuse{\pt}\pss{j}=0$, the stochastic differential equation \eqref{eq:flow} for particle motion collapses to an ordinary differential equation,
%
\begin{IEEEeqnarray}{rCl}
 \frac{d\ls{\pt}\pss{j}}{d\pt} & = & \flowdrift{\pt}\pss{j}(\ls{\pt}\pss{j})     .
\end{IEEEeqnarray}

In this case each particle is moved deterministically, and a map may be defined from the state at $\pt_0$ to that at $\pt_1$,
%
\begin{IEEEeqnarray}{rCl}
 \flowmap{\pt_0}{\pt_1} (\ls{\rt,\pt_0}\pss{j}) & = & \ls{\rt,\pt_0}\pss{j} + \int_{\pt_0}^{\pt_1} \flowdrift{\pt}\pss{j}(\ls{\rt,l}) dl     .
\end{IEEEeqnarray}

Each particle is updated by discarding the old state $\ls{\rt,\pt_0}$ and replacing it with the new $\ls{\rt,\pt_1} = \flowmap{\pt_0}{\pt_1} (\ls{\rt,\pt_0})$. The weight update associated with the transition is evaluated using standard formulas for the particle filter. Using the change of variables method, the new particle is distributed as $\impden(\ls{1:\rt-1}, \ls{\pt_1})$, where
%
\begin{IEEEeqnarray}{rCl}
 \pw{\rt,\pt_0}\pss{j} \impden(\ls{1:\rt-1}\pss{j}, \ls{\pt_1}\pss{j}) & = & \augfiltden{\pt_0}(\ls{1:\rt-1}\pss{j}, \ls{\pt_0}\pss{j}) \magdet{ \frac{\partial \ls{\rt,\pt_0}\pss{j}}{\partial \ls{\rt,\pt_1}\pss{j}} }     .
\end{IEEEeqnarray}
%
Hence, the new weights are given by,
%
\begin{IEEEeqnarray}{rCl}
 \pw{\rt,\pt_1}\pss{j} & = & \frac{ \augfiltden{\pt_1}(\ls{1:\rt-1}\pss{j}, \ls{\pt_1}\pss{j}) }{ \impden(\ls{1:\rt-1}\pss{j}, \ls{\pt_1}\pss{j}) } \nonumber \\
 & = & \pw{\rt,\pt_0}\pss{j} \frac{ p(\ob{\rt} | \ls{\rt,\pt_1}\pss{j})^{\pt_1} p(\ls{\rt,\pt_1}\pss{j} | \ls{\rt-1}\pss{j}) }{ p(\ob{\rt} | \ls{\rt,\pt_0}\pss{j})^{\pt_0} p(\ls{\rt,\pt_0}\pss{j} | \ls{\rt-1}\pss{j}) } \times \magdet{ \frac{\partial \ls{\rt,\pt_1}\pss{j}}{\partial \ls{\rt,\pt_0}\pss{j}} }   \label{eq:deterministic_weight_update}     .
\end{IEEEeqnarray}



\subsubsection{Stochastic Flows}

When $\flowdiffuse{\pt}\ne0$, the naive approach of targeting $\augfiltden{\rt,\pt_1}$ directly does not work. Suppose a new state were sampled from $\impden(\ls{\rt,\pt_1} | \ls{\rt,\pt_0}\pss{j})$, and the , the resulting importance density is,
%
\begin{IEEEeqnarray}{rCl}
 \impden(\ls{1:\rt-1},\ls{\pt_1}) & = & \int \augfiltden{\pt_0}(\ls{1:\rt-1}, \ls{\rt,\pt_0}) q(\ls{\rt,\pt_1} | \ls{\rt,\pt_0}) d\ls{\rt,\pt_0}     ,
\end{IEEEeqnarray}
%
which is generally intractable. The solution is to use an SMC sampler using the framework defined in \cite{DelMoral2006}, and used for tempering (just as we are here) in \cite{DelMoral2007}. The intractability is circumvented by employing an extended target distribution over $\ls{\rt,\pt_0}$ and $\ls{\rt,\pt_1}$ by introducing an artificial conditional density, $\artden(\ls{\rt,\pt_0} | \ls{\rt,\pt_1})$. The weight formula for this extended target is then,
%
\begin{IEEEeqnarray}{rCl}
 \pw{\rt,\pt_1}\pss{j} & = & \frac{ \augfiltden{\pt_1}(\ls{1:\rt-1}, \ls{\rt,\pt_1}) \artden(\ls{\rt,\pt_0} | \ls{\rt,\pt_1}) }{ \augfiltden{\pt_0}(\ls{1:\rt-1}, \ls{\rt,\pt_0}) \impden(\ls{\rt,\pt_1}\pss{j} | \ls{\rt,\pt_0}\pss{j}) } \nonumber \\
 & = & \pw{\rt,\pt_0}\pss{j} \frac{ p(\ob{\rt} | \ls{\rt,\pt_1})^{\pt_1} p(\ls{\rt,\pt_1} | \ls{\rt-1}) }{ p(\ob{\rt} | \ls{\rt,\pt_0})^{\pt_0} p(\ls{\rt,\pt_0} | \ls{\rt-1}) } \times \frac{ \artden(\ls{\rt,\pt_0} | \ls{\rt,\pt_1}) }{ \impden(\ls{\rt,\pt_1}\pss{j} | \ls{\rt,\pt_0}\pss{j}) } \label{eq:general_weight_update}
\end{IEEEeqnarray}
%
This is easily evaluated, after which the $\ls{\rt,\pt_0}$ states may be marginalised (i.e. simply discarded).

The importance density is found by integrating the stochastic differential equation governing the flow \eqref{eq:flow} using the selected values of $\flowdrift{\pt}$ and $\flowdiffuse{\pt}$. The optimal choice for the artificial conditional density (in the sense of minimising the weight variance) is shown in \cite{DelMoral2006} to be,
%
\begin{IEEEeqnarray}{rCl}
 \artden(\ls{\rt,\pt_0}\pss{j} | \ls{\rt,\pt_1}\pss{j}) & = & \frac{ \oiden{\pt_0}(\ls{\rt,\pt_0} | \ls{\rt-1}) \impden(\ls{\rt,\pt_1} | \ls{\rt,\pt_0}) }{ \int \oiden{\pt_0}(\ls{} | \ls{\rt-1}) \impden(\ls{\rt,\pt_1} | \ls{}) d\ls{} } \label{eq:optimal_artificial_density}     .
\end{IEEEeqnarray}







\appendix

\section{Proof of Lemma~\ref{lem:optimal_flow_governing_eq}: Governing Equation for the Optimal Flow} \label{app:optimal_flow_governing_eq}

This derivation is based closely on the exposition of \citep{Daum2008}, except that each particle is moved according to a sequence ending in the OID, rather than the filtering density. Time subscripts, particle superscripts and the dependence on $\ls{\rt-1}$ are omitted for clarity. In addition, the transition and observation densities are written as,
%
\begin{IEEEeqnarray}{rCl}
 \flowtd(\ls{}) & = & p(\ls{}|\ls{\rt-1}) \nonumber \\
 \flowod(\ls{}) & = & p(\ob{\rt}|\ls{}) \nonumber      .
\end{IEEEeqnarray}

An equation for the optimal flow may be derived by considering the sequence of densities, $\oiden{\pt}(\ls{\pt})$. Taking the log and differentiating with respect to $\pt$ and $\ls{\pt}$,
%
\begin{IEEEeqnarray}{rCl}
 \log\left( \oiden{\pt}(\ls{\pt}) \right) & = & \log\left( \flowtd(\ls{\pt}) \right) + \pt \log\left( \flowod(\ls{\pt}) \right) - \log\left(\oinorm{\pt}\right)     ,
\end{IEEEeqnarray}
%
\begin{IEEEeqnarray}{rCl}
 \frac{\partial}{\partial \pt} \log\left( \oiden{\pt}(\ls{\pt}) \right) & = & \frac{ 1 }{ \oiden{\pt}(\ls{\pt}) } \frac{\partial \oiden{\pt}}{\partial \pt} \nonumber \\
  & = & \log\left(\flowod(\ls{\pt})\right) - \frac{d}{d\pt}\log\left(\oinorm{\pt}\right) \label{eq:dpi-dlam}     ,
\end{IEEEeqnarray}
%
\begin{IEEEeqnarray}{rCl}
 \nabla \log\left( \oiden{\pt}(\ls{\pt}) \right) & = & \frac{ 1 }{ \oiden{\pt}(\ls{\pt}) } \nabla \oiden{\pt}(\ls{\pt}) \label{eq:dpi-dx}     .
\end{IEEEeqnarray}
%
The Fokker-Planck equation relates the motion of a particle with the evolution of the density for its position. For a particle moving according to,
%
\begin{IEEEeqnarray}{rCl}
 d\ls{\pt} & = & \flowdrift{\pt}(\ls{\pt}) d\pt + \flowdiffuse{\pt} d\flowbm{\pt}     ,
\end{IEEEeqnarray}
%
Fokker-Planck states,
%
\begin{IEEEeqnarray}{rCl}
 \frac{\partial \oiden{\pt}}{\partial \pt} & = & - \nabla \cdot \left[ \flowdrift{\pt}(\ls{\pt}) \oiden{\pt}(\ls{\pt}) \right] + \nabla \cdot \left[ \flowcov{\pt} \nabla \oiden{\pt}(\ls{\pt}) \right]     .
\end{IEEEeqnarray}
%
Substituting \eqref{eq:dpi-dlam} and \eqref{eq:dpi-dx}, we have,
%
\begin{IEEEeqnarray}{rCl}
 \frac{\partial \oiden{\pt}}{\partial \pt} & = & -\nabla \cdot \left[ \flowdrift{\pt}(\ls{\pt}) \oiden{\pt}(\ls{\pt}) \right] + \nabla \cdot \left[ \flowcov{\pt} \nabla \oiden{\pt}(\ls{\pt}) \right]     \nonumber \\
 \oiden{\pt}(\ls{\pt}) \left[ \log\left(\flowod(\ls{\pt})\right) - \frac{d}{d\pt}\log\left(\oinorm{\pt}\right) \right] & = & -\nabla\cdot \flowdrift{\pt}(\ls{\pt}) \oiden{\pt}(\ls{\pt}) - \flowdrift{\pt}(\ls{\pt}) \cdot \nabla \oiden{\pt}(\ls{\pt}) \nonumber \\
 &   & \qquad \qquad + \: \nabla \cdot \left[ \flowcov{\pt} \nabla \oiden{\pt}(\ls{\pt}) \right] \nonumber \\
 \left[ \log\left(\flowod(\ls{\pt})\right) - \frac{d}{d\pt}\log\left(\oinorm{\pt}\right) \right] & = & -\nabla\cdot \flowdrift{\pt}(\ls{\pt}) - \flowdrift{\pt}(\ls{\pt}) \cdot \nabla \log\left( \oiden{\pt}(\ls{\pt}) \right) \nonumber \\
 &   & \qquad \qquad + \: \frac{ 1 }{ \oiden{\pt}(\ls{\pt}) } \nabla \cdot \left[ \flowcov{\pt} \nabla \oiden{\pt}(\ls{\pt}) \right]     ,
\end{IEEEeqnarray}
%
where the last step is a division through by $\oiden{\pt}$. This requires the density to be nowhere vanishing. Finally consider the normalising constant,
%
\begin{IEEEeqnarray}{rCl}
 \frac{d}{d\pt}\log\left(\oinorm{\pt}\right) & = & \frac{\frac{d\oinorm{\pt}}{d\pt}}{\oinorm{\pt}} \nonumber \\
                                               & = & \frac{ \int \flowtd(\ls{\pt}) \flowod(\ls{\pt})^\pt \log\left(\flowod(\ls{\pt})\right) d\ls{\rt} }{ \int \flowtd(\ls{\pt}) \flowod(\ls{\pt})^\pt d\ls{\pt} } \nonumber \\
                                               & = & \expect{\oiden{\pt}}\left[ \log\left(\flowod(\ls{\pt})\right) \right]     .
\end{IEEEeqnarray}
%
Thus,
%
\begin{IEEEeqnarray}{rCl}
\log\left(\flowod(\ls{\pt})\right) - \expect{\oiden{\pt}}\left[ \log\left(\flowod(\ls{\pt})\right) \right] & = & -\nabla\cdot \flowdrift{\pt}(\ls{\pt}) - \flowdrift{\pt}(\ls{\pt}) \cdot \nabla \log\left( \oiden{\pt}(\ls{\pt}) \right) \nonumber \\
 &   & \qquad + \: \frac{1}{\oiden{\pt}(\ls{\pt})} \nabla \cdot \left[ \flowcov{\pt} \nabla \oiden{\pt}(\ls{\pt}) \right] \label{app-eq:optimal_flow_PDE}      .
\end{IEEEeqnarray}

This is a partial differential equation (PDE), for which any solution, $\flowdrift{\pt}$ and $\flowdiffuse{\pt}$, gives an optimal flow.











\bibliographystyle{chicago}
\bibliography{D:/pb404/Dropbox/PhD/OTbib}

\end{document} 