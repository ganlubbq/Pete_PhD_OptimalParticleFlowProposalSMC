\documentclass[a4paper,10pt]{article}
\usepackage[utf8x]{inputenc}

%%% PACKAGES %%%
% Graphics
\usepackage[pdftex]{graphicx}
\usepackage[caption=false,font=footnotesize]{subfig}
% Formatting
\usepackage{color}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{bbm}
\usepackage[T1]{fontenc}
\usepackage{pandora}
\linespread{1.2}
% Environments
\usepackage{IEEEtrantools}
\usepackage{algorithm}
\usepackage{algorithmic}
% References
%\usepackage{harvard}

\graphicspath{{./}}

% My environments
\newenvironment{meta}[0]{\color{red} \em}{}

%%% Notational shortcuts %%%

% Functions and operators
\newcommand{\expect}[1]{\mathbb{E}_{#1}}                    % Expectation
\newcommand{\variance}[1]{\mathbb{V}_{#1}}                    % Variance
\DeclareMathOperator{\trace}{Tr}                            % Trace
\newcommand{\magdet}[1]{\left|\left| #1 \right|\right|}     % Magnitude of the determinant
\newcommand{\indic}[1]{\mathbbm{1}_{#1}}                    % Indicator function
\newcommand{\normal}[3]{\mathcal{N}\left(#1|#2,#3\right)}   % Normal density

% Basics
\newcommand{\rt}{t}                             % Real time
\newcommand{\pt}{\lambda}                       % Pseudo-time
\newcommand{\ls}[1]{x_{#1}}                     % Latent state
\newcommand{\ob}[1]{y_{#1}}                     % Observation
\newcommand{\linob}[1]{\tilde{y}_{#1}}          % Linearised bservation

% Particle shizzle
\newcommand{\pss}[2][]{^{(#2)#1}}               % Particle superscript
\newcommand{\pw}[1]{w_{#1}}                     % Particle weight
\newcommand{\npw}[1]{\bar{w}_{#1}}              % Normalised particle weight
\newcommand{\naw}[1]{\bar{v}_{#1}}              % Normalised auxiliary weight
\newcommand{\anc}[1]{a_{#1}}                    % Particle ancestor

% Densities
\newcommand{\impden}{q}                         % Importance density
\newcommand{\artden}{\rho}                      % Artificial conditional density
\newcommand{\oiden}[1]{\pi_{#1}}                % Optimal importance density
\newcommand{\augfiltden}[1]{\tilde{\pi}_{#1}}   % Augmented filtering density
\newcommand{\oinorm}[1]{K_{#1}}                 % Normalising constant for the optimal importance density
\newcommand{\augfiltnorm}[1]{\tilde{K}_{#1}}    % Normalising constant for the augmented filtering density

% Numbers
\newcommand{\numpart}{N_F}                      % Number of filter particles
\newcommand{\ess}[1]{N_{E,#1}}                  % Effective sample size

% Particle flow
\newcommand{\flowbm}[1]{\epsilon_{#1}}          % Particle flow Brownian motion
\newcommand{\flowdrift}[1]{\zeta_{#1}}          % Particle flow drift
\newcommand{\flowdiffuse}[1]{\eta_{#1}}         % Particle flow diffusion
\newcommand{\flowcov}[1]{D_{#1}}                % Particle flow "Covariance" matrix
\newcommand{\flowtd}{\alpha}                    % Flow dervation transition density
\newcommand{\flowod}{\beta}                     % Flow derivation observation density
\newcommand{\flowmap}[2]{\phi_{#1}^{#2}}        % Flow transport map

% Linear flow
\newcommand{\lfmat}[1]{A_{#1}}                  % Linear flow matrix
\newcommand{\lfshift}[1]{b_{#1}}                % Linear flow shift
\newcommand{\lfdiffsf}{\gamma}                  % Linear flow diffusion matrix scale factor

% Models
\newcommand{\transfun}{f}                       % Transition function
\newcommand{\obsfun}{h}                         % Observation function
\newcommand{\transcov}{Q}                       % Transition covariance
\newcommand{\obscov}{R}                         % Observation covariance
\newcommand{\obsmat}{H}                         % Linear observation matrix
\newcommand{\transmean}{m}                      % Mean of the transition density (i.e. f(x_{t-1}))

% Linear Gaussian things
\newcommand{\lgoimean}[1]{\mu_{#1}}             % Linear Gaussian optimal importance density mean
\newcommand{\lgoicov}[1]{\Sigma_{#1}}           % Linear Gaussian optimal importance density covariance
\newcommand{\lginterm}[1]{S_{#1}}               % Useful intermediate term equal to \transcov / \lgoicov


%%% OLD SHORTCUTS %%%
\newcommand{\tilpit}[1]{\tilde{\pi}_{t,#1}}
\newcommand{\pit}[1]{\pi_{t,#1}}
\newcommand{\xt}[1]{x_{t,#1}}
\newcommand{\wt}[1]{w_{t,#1}}

\newcommand{\lam}[1]{{#1}_{\lambda}}
\newcommand{\pilam}{\pi_{\lambda}}

\newcommand{\pij}{^{(j)}}
\newcommand{\pii}{^{(i)}}


%%% OLD OLD SHORTCUTS %%%
\newcommand{\tilpitlam}{\tilde{\pi}_{t,\lambda}}
\newcommand{\tilpitldl}{\tilde{\pi}_{t,\lambda+\delta\lambda}}
\newcommand{\pitlam}{\pi_{t,\lambda}}
\newcommand{\xtlam}{x_{t,\lambda}}
\newcommand{\xtztl}{x_{t,0:\lambda}}
\newcommand{\xtl}{x_{t,\lambda}}
\newcommand{\xtldl}{x_{t,\lambda+\delta\lambda}}
\newcommand{\tilpilam}{\tilde{\pi}_{\lambda}}
\newcommand{\tilpildl}{\tilde{\pi}_{\lambda+\delta\lambda}}
\newcommand{\pildl}{\pi_{\lambda+\delta\lambda}}
\newcommand{\piztl}{\pi_{0:\lambda}}
\newcommand{\piztldl}{\pi_{0:\lambda+\delta\lambda}}
\newcommand{\xlam}{x_{\lambda}}
\newcommand{\xldl}{x_{\lambda+\delta\lambda}}
\newcommand{\xztl}{x_{0:\lambda}}
\newcommand{\xztldl}{x_{0:\lambda+\delta\lambda}}
\newcommand{\flam}{f_{\lambda}}
\newcommand{\glam}{g_{\lambda}}
\newcommand{\Dlam}{D_{\lambda}}
\newcommand{\xtraj}{\tilde{x}_{0:\lambda}}
\newcommand{\W}{\mathbf{W}}

%opening
\title{The Smooth Update Particle Filter}
\author{Pete Bunch}
\date{March 2013}

\begin{document}

\maketitle

\begin{abstract}
\end{abstract}

\section{Introduction}

A particle filter is an algorithm used for sequential estimation of a filtering distribution for a state-space model. For a comprehensive introduction, see for example \cite{Cappe2007,Doucet2009}. In this paper we consider the use of particle filters for inference with a standard discrete-time hidden Markov model (HMM).

The particle filter advances a set of samples through time, drawn approximately from the filtering distribution. This is achieved by sampling at each time step from an importance distribution and then weighting the particles to account for the discrepancy between target and importance distributions. Particles filters have attractive asymptotic properties: as the number of particles is increased, estimates are guaranteed to converge to their true values.

One of the principal difficulties when designing a particle filter is the selection of the importance distribution. The easiest choice is often to sample from the transition model, which leads to a simplification in the weight formula. The resulting algorithm is the ``bootstrap filter'' of \cite{Gordon1993}. In many cases, such bootstrap proposals result in poor filter performance due to a mismatch in the areas of high probability in the transition and observation distributions.

Amongst others, \cite{Doucet2000a} demonstrated that the ideal choice of importance distribution is the conditional posterior given both the previous state and the new observation, dubbed the ``optimal importance distribution'' (OID). In all but a few cases, this cannot be calculated analytically. When the state variables are continuous, a popular solution is to use an extended (EKF) or unscented (UKF) Kalman filter to select a Gaussian importance distribution. However, such schemes can fail when the model is highly nonlinear or non-Gaussian, as the approximation is poor.

The effect of using a poor importance distribution (i.e. one which is not ``close'' to the OID) is that the variance of the importance weights is increased, resulting in a degeneracy of the filter. In the worst cases, there may be no particles proposed in regions of high posterior probability, causing the filter to diverge.

Many solutions to the problem of particle filter degeneracy have been proposed, including the addition of Markov chain Monte Carlo (MCMC) steps to regenerate a particle approximation \cite{Gilks2001} and the marginalisation of variables which can be filtered analytically, a process known as ``Rao-Blackwellisation'' \cite{Casella1996,Doucet2000}. Degeneracy can also be mitigated by introducing the effect of each observation gradually, so that particles are progressively drawn towards peaks in the likelihood. This idea of tempering using a discrete set of bridging distributions between the prior and the posterior has appeared, for example, in \cite{Godsill2001b}.

More recently, methods have been proposed which define a continuous sequence of distributions between the prior and the posterior. The set of particles is then moved deterministically so that they are always distributed accordingly. Filtering algorithms based on this idea of particle flow or transport have been developed independently by \cite{Daum2008,Daum2011d} and \cite{Reich2011}, and for static state spaces by \cite{Moselhy2012}. Such particle flow filters have some clear advantages: they maintain equally weighted particles throughout and are thus readily parallelised. However, some of the attractive properties of normal particle filters are not retained. Because flows can rarely (if ever) be calculated analytically, approximations must be made, resulting in the loss of asymptotic consistency. There is also a loss in flexibility: Flow-based filters can be applied only to unbounded continuous state spaces; they cannot handle discrete variables such as indicators.

In this paper, we devise a new ``smooth update'' particle filter which, rather than applying a particle flow directly to the filtering distribution, uses it to generate samples from an approximation of the OID. By moving the approximations into the proposal step, we recover the asymptotic properties of the particle filter, at the expense of parallelism. Mixed and bounded state-space also present no obstacle. The algorithm is based on the standard framework of Sequential Monte Carlo Samplers \cite{DelMoral2006}, with the target distribution being extended over the state trajectory induced by during the filter update. The approximately optimal flow we employ is derived by first solving the dynamical equations for a linear Gaussian model, and then by making suitable local approximations to this model for all other cases, in a fashion roughly analogous to the EKF.

Having covered some particle filter basics in section, we introduce a framework for new algorithm in section . In section , an optimal solution is derived for the linear Gaussian case, and in section , this is employed as a tool for implementing quasi-optimal solutions for other models. Numerical illustrations are presented in section .



\section{Particle Filtering}

\subsection{Some Basics}

We consider a standard discrete-time HMM in which the transition, observation and prior models have closed-form densities,
%
\begin{IEEEeqnarray}{rCl}
 \ls{\rt} & \sim & p(\ls{\rt} | \ls{\rt-1}) \label{eq:td} \\
 \ob{\rt} & \sim & p(\ob{\rt} | \ls{\rt})   \label{eq:od} \\
 \ls{1} & \sim & p(\ls{1})                  \label{eq:pd}      ,
\end{IEEEeqnarray}
%
where the random variable $\ls{\rt}$ is the hidden state of a system at time $\rt$, and $\ob{\rt}$ is an incomplete, noisy observation. We assume here that the transition, observation and prior densities may be evaluated and that the prior and transition densities may be sampled.

A particle filter is used to estimate the distribution over the path of the state variables, $\ls{1:\rt}=\{\ls{1}, \dots, \ls{\rt}\}$, (we will refer to this as the ``filtering distribution'', although this term more conventionally refers to the distribution of the latest state only, not the entire path) which has the following density,
%
\begin{IEEEeqnarray}{rCl}
 p(\ls{1:\rt} | \ob{1:\rt}) & = & \frac{ p(\ls{1}) \prod_{k=2}^{\rt} p(\ob{k}|\ls{k}) p(\ls{k}|\ls{k-1}) }{ \int p(\ls{0}) \prod_{k=1}^{\rt} p(\ob{k}|\ls{k}) p(\ls{k}|\ls{k-1}) d\ls{1:\rt} }     .
\end{IEEEeqnarray}

A particle filter approximates the filtering density with a set of weighted particles drawn approximately from it using sequential importance sampling,
%
\begin{IEEEeqnarray}{rCl}
 p(\ls{1:\rt} | \ob{1:\rt}) & = & \sum_i \npw{\rt}\pss{i} \delta_{\ls{1:\rt}\pss{i}}(\ls{1:\rt})     ,
\end{IEEEeqnarray}
%
where $\delta_{\ls{1:\rt}\pss{i}}(\ls{1:\rt})$ denotes a unit probability mass at the point $\ls{1:\rt}\pss{i}$. (To be precise, the associated probability measure consists of a sum of weighted indicator functions at these points.)

A particle is generated at time $\rt$ by first selecting a parent from amongst the $\rt-1$ particles; an index, $\anc{j}$, is chosen with probability (or ``auxiliary weight'') $\naw{t-1}\pss{j}$. Next, a new state $\ls{\rt}\pss{j}$ is sampled from an importance density, $\impden(\ls{\rt} | \ls{\rt-1}\pss{\anc{j}}, \ob{\rt})$, and concatenated to the parent path to form the new particle,
%
\begin{IEEEeqnarray}{rCl}
 \ls{1:\rt}\pss{j} \leftarrow \left\{ \ls{1:\rt-1}\pss{\anc{j}},  \ls{\rt}\pss{j} \right\}     .
\end{IEEEeqnarray}
%
Finally, an importance weight is assigned to the particle to account for the discrepancy between importance and target distributions,
%
\begin{IEEEeqnarray}{rCl}
 \pw{\rt}\pss{j} & = & \frac{ p(\ls{1:\rt}\pss{j} | \ob{1:\rt}) }{ p(\ls{1:\rt-1}\pss{\anc{j}} | \ob{1:\rt-1}) \impden(\ls{\rt}\pss{j} | \ls{\rt-1}\pss{\anc{j}}, \ob{\rt}) } \nonumber \\
 & \propto & \frac{\npw{\rt-1}\pss{j}}{\naw{t-1}\pss{j}} \times \frac{ p(\ob{\rt} | \ls{\rt}\pss{j}) p(\ls{\rt}\pss{j} | \ls{\rt-1}\pss{\anc{j}}) }{ \impden(\ls{\rt}\pss{j} | \ls{\rt-1}\pss{\anc{j}}, \ob{\rt}) }     ,
\end{IEEEeqnarray}
%
and the weights are normalised,
%
\begin{IEEEeqnarray}{rCl}
 \npw{\rt} & = & \frac{ \pw{\rt}\pss{j} }{ \sum_i \pw{\rt}\pss{i} }      .
\end{IEEEeqnarray}

In some cases, the distributions concerned will not have valid densities. In this case, the particle weights can still be legitimately defined as the ratio of target and importance measures, {\meta cite something}
%
\begin{IEEEeqnarray}{rCl}
 \pw{\rt}\pss{j} & \propto & \frac{\npw{\rt-1}\pss{j}}{\naw{t-1}\pss{j}} \times \frac{ p(\ob{\rt} | \ls{\rt}\pss{j}) p(d\ls{\rt}\pss{j} | \ls{\rt-1}\pss{\anc{j}}) }{ \impden(d\ls{\rt}\pss{j} | \ls{\rt-1}\pss{\anc{j}}, \ob{\rt}) }     .
\end{IEEEeqnarray}
%
Particle filters are ``exact'' in the sense that as the number of particles tends to infinite, integrals over the density converge to the true value.

The practical performance of the particle filter is determined by the variance of the weights. If this is high, then only a small proportion of the particles (perhaps only one) will be significant, and only these will be taken forward to the next filtering step. Clearly, a lower number of significant particles leads to a poorer representation of the distribution, resulting in an increased estimator variance and propensity for the filter to diverge or ``lose track''. The particle weight variance may be measured using the effective sample size (ESS), defined as,
%
\begin{IEEEeqnarray}{rCl}
 \ess{\rt} & = & \frac{ 1 }{ \sum_i \npw{\rt}\pss[2]{i} }     ,
\end{IEEEeqnarray}
%
Intuitively, this is the number of particles which would be present in an set of equivalent quality comprised of independent, unweighted samples. It takes a value between $1$ (which is bad) and the number of filtering particles, $\numpart$ (which is good).

The final consideration for the basic particle filter is the choice of the auxiliary weights, $\{\naw{t-1}\pss{i}\}$ and the method for sampling parent indexes, which together constitute a ``resampling'' step. If resampling is conducted before the effect of the new observation is introduced, then it is clear that the weight variance is minimised by choosing $\naw{t-1}\pss{i}=\npw{t-1}\pss{i}$. However, since resampling can be an expensive step (for example, it cannot be easily parallelised), it may often be better simply to keep the same set of particles as generated at the previous time if the weights are not widely spread. This corresponds to using $\naw{t-1}\pss{i}=1/\numpart$.

\subsection{Importance Distributions}

The simplest choice of importance density is the transition density,
%
\begin{IEEEeqnarray}{rCl}
 \impden(\ls{\rt} | \ls{\rt-1}\pss{\anc{j}}, \ob{\rt}) = p(\ls{\rt} | \ls{\rt-1}\pss{\anc{j}})     .
\end{IEEEeqnarray}
%
This results in the ``bootstrap filter'' of \cite{Gordon1993}. It is very simple and only requires that samples may be drawn from the transition distribution, and not that the transition density be calculable. The weight formula simplifies to,
%
\begin{IEEEeqnarray}{rCl}
 \pw{\rt}\pss{j} & \propto & \frac{\npw{\rt-1}\pss{j}}{\naw{\rt-1}\pss{j}} \times p(\ob{\rt} | \ls{\rt}\pss{j}) \label{eq:weight_update_bootstrap}      ,
\end{IEEEeqnarray}
%
Often the bootstrap filter is inefficient, especially when the variance of the transition density is greater than that of the observation density. In this situation, the samples are widely spread over the state space, and only a few fall in the region of high likelihood. This results in a large weight variance and poor filter performance.

It was shown in \cite{Doucet2000a}, and references therein, that the weight variance is minimised by using the conditional posterior as the importance distribution,
%
\begin{IEEEeqnarray}{rCl}
 \impden(\ls{\rt} | \ls{\rt-1}\pss{\anc{j}}, \ob{\rt}) & = & p(\ls{\rt} | \ls{\rt-1}\pss{\anc{j}}, \ob{\rt})      ,
\end{IEEEeqnarray}
%
resulting in the following weight formula,
%
\begin{IEEEeqnarray}{rCl}
 \pw{\rt}\pss{j} & \propto & \frac{\npw{\rt-1}\pss{j}}{\naw{\rt-1}\pss{j}} \times p(\ob{\rt} | \ls{\rt-1}\pss{\anc{j}}) \nonumber \\
           & \propto & \frac{\npw{\rt-1}\pss{j}}{\naw{\rt-1}\pss{j}} \times \int p(\ob{\rt} | \ls{\rt}) p(\ls{\rt} | \ls{\rt-1}\pss{\anc{j}}) d\ls{\rt}      .
\end{IEEEeqnarray}
%
This choice is thus known as the ``optimal importance density'' (OID). It may be sampled from, and the weights calculated in closed form, when the observation density is linearly dependent on the state and both transition and observation densities are Gaussian. (The state need not be linearly dependent on the previous state.) However, for most models this density can be neither calculated, nor efficiently sampled from. Thus, it is common to use the same Gaussian approximations to estimate and sample from the OID as were used in the formulation of the EKF and UKF \cite{Doucet2000a,Merwe2000}. These work well when the OID is unimodal, and the observation nonlinearity is weak, but can otherwise perform worse even than the bootstrap filter.

\subsection{Predict-Update}

The operations of the particle filter can be divided up into a prediction step and an update step. This is particularly true of the bootstrap filter, and will be a helpful framework for considering the new algorithm.

In the predict step of the bootstrap filter, a new state is sampled for each particle from the transition density, $p(\ls{\rt}|\ls{\rt-1}\pss{\anc{j}})$. The extended particles formed in this process form an approximation to the predictive distribution, $p(\ls{1:\rt}|\ob{1:\rt-1})$, using the associated weights,
%
\begin{IEEEeqnarray}{rCl}
 \pw{\rt}\pss{j} & \propto & \frac{\npw{\rt-1}\pss{j}}{\naw{\rt-1}\pss{j}}       .
\end{IEEEeqnarray}

In the update step, the effects of the new observation, $\ob{\rt}$, are introduced by assigning a new weight according to \eqref{eq:weight_update_bootstrap}. The problems of filter degeneracy originate solely in the update step. The new algorithm modifies this step so that both state and weight are changed.



\section{Existing Particle Flow Methods}

At the heart of our new algorithm lies the concept of an optimal particle flow, which has been employed in particle filters by \cite{Daum2008,Daum2011d,Reich2011}. Details of these methods will not be presented here, but since they form the the inspiration and the starting point for our endeavours, it is apposite to include an overview of their operation and a discussion of their characteristics.

The leap of insight made in \cite{Daum2008}, was to introduce a continuous sequence of densities between the predictive, $p(\ls{\rt}|\ob{1:\rt-1})$, and filtering, $p(\ls{\rt}|\ob{1:\rt})$, densities, parameterised by a ``pseudo-time'' variable which increases from $0$ to $1$. Each frame of the filtering algorithm begins with the sampling of a set of particles from the predictive density. The particles are then moved deterministically according to a (pseudo-)time-varying flow field which ensures that the particles are distributed appropriately. Hence, at the end of the pseudo-time interval, the particle distribution will match the filtering distribution. An appropriate, optimal flow field is derived by using the Fokker-Planck equation, which relates the evolution of densities (which is specified) to the corresponding flow of particles.

While theoretically extremely elegant, such an algorithm suffers from a number of drawbacks. Foremost of which, there is only one model for which the optimal flow can be derived and integrated analytically: the linear Gaussian case, for which we already have the far more efficient Kalman filter. For every other model, it is necessary to make either numerical or functional approximations in order to evaluate an optimal flow, on top of which the flow must then be numerically integrated. For example, it seems generally to be required that it be possible to evaluate the filtering density at arbitrary points. This is addressed in \cite{Daum2012} by using a Monte Carlo approximation, and in \cite{Reich2012a} by using a Gaussian-mixture approximation. The problem with these approximations is that they alter the distribution of the particles such that it is no longer exactly equal to the filtering distribution. The manner and degree of this divergence is not easily quantified. Hence, these particle flow methods do not have the appealing asymptotic consistency of an ordinary particle filter.

A further limitation of the particle flow algorithms described by \cite{Daum2011d} is their restriction to certain classes of state space. Only continuous states can be handled, and for these the density must be nowhere vanishing. Bounds on the state, such as are frequently available in physical problems, cannot be handled easily.

Our new algorithm, which we dub the smooth update particle filter (SUPF), addresses these limitations by using a particle flow to draw samples from an approximation to the OID, rather than from the filtering distribution directly. This is achieved within the framework of a standard sequential Monte Carlo (SMC) sampler \cite{DelMoral2006,DelMoral2007} employed for tempering. One of the appeals of the filters of \cite{Daum2011d,Reich2011} is the fact that the particles are uniformly weighted throughout, and thus they do not require any resampling. It is this property that we sacrifice in order to achieve these improvements.



\section{A Framework for the Smooth Update}

We split each iteration of the particle filter into two steps: a prediction and an update. Prediction consists of the usual selection step and sampling from the transition density, (exactly the same as the bootstrap filter), and results in weighted set of particles approximating the predictive density, $p(\ls{1:\rt}|\ob{1:\rt-1})$. The novelty lies in the update step.

First, as in \cite{Daum2011d}, a variable $\pt \in [0,1]$ is introduced. Intuitively, this is a stretch of ``pseudo-time'' between the predictive and filtering distributions, allowing the effect of the observation to be introduced gradually. Define $\ls{\rt,\pt}$ as the state at time $\rt$ and pseudo-time $\pt$.

Now we define a continuous sequence of target densities,
%
\begin{IEEEeqnarray}{rCl}
 \augfiltden{\rt,\pt}(\ls{1:\rt-1}, \ls{\rt,\pt}) & = & \frac{ p(\ob{\rt} | \ls{\rt,\pt})^{\pt} p(\ls{\rt,\pt} | \ls{\rt-1}) p(\ls{1:\rt-1}|\ob{1:\rt-1}) }{ \augfiltnorm{\pt} } \nonumber \\
 \augfiltnorm{\pt} & = & \int p(\ob{\rt} | \ls{\rt,\pt})^{\pt} p(\ls{\rt,\pt} | \ob{1:\rt-1}) d\ls{\rt,\pt}      .
\end{IEEEeqnarray}
%
This is equal to the predictive density when $\pt=0$ and the desired filtering density when $\lambda=1$. Rather than attempting to propose particles directly to approximate $p(\ls{1:\rt}|\ob{1:\rt})$, we begin with our predictive particles sampled from the transition density and move incrementally through pseudo-time, targeting $\augfiltden{\rt,\pt}$ with an SMC sampler.

\subsection{SMC Sampling}

Here we consider a generic SMC method for advancing the particle approximation through pseudo-time. This closely follows the framework defined in \cite{DelMoral2006}, and used for tempering in \cite{DelMoral2007}. Assume we have a set of particles $\{\ls{\rt,\pt_0}\pss{i}\}$ with weights $\{\pw{\rt,\pt_0}\pss{i}\}$ approximating $\augfiltden{\pt_0}$ and consider the change between $\pt_0$ and a later pseudo-time $\pt_1$. For the $(j)$th particle, a new state, $\ls{\rt,\pt_1}\pss{j}$ is sampled from an importance density, $q(\ls{\rt,\pt_1}\pss{j} | \ls{\rt,\pt_0}\pss{j})$. We wish to target the $\augfiltden{\pt_1}$; however, this would lead to a (usually intractable) integral in evaluating the associated particle weight,
%
\begin{IEEEeqnarray}{rCl}
 \pw{\rt,\pt_1}\pss{j} & = & \frac{ \augfiltden{\pt_1}(\ls{1:\rt-1}, \ls{\rt,\pt_1}) }{ \int \augfiltden{\pt_1}(\ls{1:\rt-1}, \ls{\rt,\pt_0}) q(\ls{\rt,\pt_1}\pss{j} | \ls{\rt,\pt_0}\pss{j}) d\ls{\rt,\pt_0} } \nonumber     .
\end{IEEEeqnarray}
%
To circumvent this intractability, an SMC sampler \cite{DelMoral2006} employs an extended target distribution over $\ls{\rt,\pt_0}$ and $\ls{\rt,\pt_1}$ by introducing an artificial conditional density, $\artden(\ls{\rt,\pt_0} | \ls{\rt,\pt_1})$. The weight formula for this extended target is then,
%
\begin{IEEEeqnarray}{rCl}
 \pw{\rt,\pt_1}\pss{j} & = & \frac{ \augfiltden{\pt_1}(\ls{1:\rt-1}, \ls{\rt,\pt_1}) \artden(\ls{\rt,\pt_0} | \ls{\rt,\pt_1}) }{ \augfiltden{\pt_1}(\ls{1:\rt-1}, \ls{\rt,\pt_0}) \impden(\ls{\rt,\pt_1}\pss{j} | \ls{\rt,\pt_0}\pss{j}) } \nonumber \\
 & = & \pw{\rt,\pt_0}\pss{j} \frac{ p(\ob{\rt} | \ls{\rt,\pt_1})^{\pt_1} p(\ls{\rt,\pt_1} | \ls{\rt-1}) }{ p(\ob{\rt} | \ls{\rt,\pt_0})^{\pt_0} p(\ls{\rt,\pt_0} | \ls{\rt-1}) } \times \frac{ \artden(\ls{\rt,\pt_0} | \ls{\rt,\pt_1}) }{ \impden(\ls{\rt,\pt_1}\pss{j} | \ls{\rt,\pt_0}\pss{j}) } \label{eq:general_weight_update}
\end{IEEEeqnarray}
%
This is easily evaluated, after which the $\ls{\rt,\pt_0}$ states may be marginalised (i.e. simply discarded).



\subsection{The Optimal Particle Flow}

Within the SMC framework, the task is now to move the particles in an optimal manner so as to minimise the weight variance. We achieve this by considering the family of optimal importance densities corresponding to $\augfiltden{\rt,\pt}$. For the $(j)$th particle, this is defined by,
%
\begin{IEEEeqnarray}{rCl}
 \oiden{\rt,\pt}(\ls{\rt,\pt} | \ls{\rt-1}\pss{\anc{j}}) & = & \frac{ p(\ob{\rt} | \ls{\rt,\pt})^{\pt} p(\ls{\rt,\pt} | \ls{\rt-1}\pss{\anc{j}}) }{ \oinorm{\pt}(\ls{\rt-1}\pss{\anc{j}}) } \nonumber \\
 \oinorm{\pt}(\ls{\rt-1}\pss{\anc{j}}) & = & \int p(\ob{\rt} | \ls{\rt,\pt})^{\pt} p(\ls{\rt,\pt} | \ls{\rt-1}\pss{\anc{j}}) d\ls{\rt,\pt}      .
\end{IEEEeqnarray}
%
Hence, $\oiden{\rt,0}$ is the transition density and $\oiden{\rt,1}$ the usual OID.

As pseudo-time advances from $0$ to $1$, particles are moved according to a stochastic differential equation (time subscripts $\rt$ omitted for clarity),
%
\begin{IEEEeqnarray}{rCl}
 d\ls{\pt}\pss{j} & = & \flowdrift{\pt}\pss{j}(\ls{\pt}\pss{j}) d\pt + \flowdiffuse{\pt}\pss{j} d\flowbm{\pt}\pss{j} \label{eq:flow}     ,
\end{IEEEeqnarray}
%
where $\flowbm{\pt}\pss{j}$ is a Brownian motion. Note that a more general case in which $\flowdiffuse{\pt}$ depended on $\ls{\pt}$ could also be used, but this has not been investigated.

An optimal particle flow is produced by selecting $\flowdrift{\pt}\pss{j}$ and $\flowdiffuse{\pt}\pss{j}$ such that each particle, $\ls{\pt}\pss{j}$, is distributed according to $\oiden{\rt,\pt}(\ls{\rt,\pt} | \ls{\rt-1}\pss{\anc{j}})$, since this results in the OID at the end of the pseudo-time interval. The interaction between particle motion and evolution of densities is governed by the Fokker-Planck equation, consideration of which leads us to the following relationship,
%
\begin{IEEEeqnarray}{rCl}
\log\left(\flowod(\ls{\pt})\right) - \expect{\oiden{\pt}}\left[ \log\left(\flowod(\ls{\pt})\right) \right] & = & -\nabla\cdot \flowdrift{\pt}(\ls{\pt}) - \flowdrift{\pt}(\ls{\pt}) \cdot \nabla \log\left( \oiden{\pt}(\ls{\pt}) \right) \nonumber \\
 &   & \qquad + \: \frac{1}{\oiden{\pt}(\ls{\pt})} \nabla \cdot \left[ \flowcov{\pt} \nabla \oiden{\pt}(\ls{\pt}) \right] \label{eq:optimal_flow_PDE}      ,
\end{IEEEeqnarray}
%
where
%
\begin{IEEEeqnarray}{rCl}
 \flowod(\ls{}) & = & p(\ob{\rt}|\ls{}) \nonumber \\
 \flowcov{\pt} & = & \frac{1}{2} \flowdiffuse{\pt} \flowdiffuse{\pt}^T \nonumber      .
\end{IEEEeqnarray}
%
For proof, see Appendix \ref{app:optimal_flow_governing_eq}.

Once the flow has been determined, it can integrated in order to establish an optimal choice for the importance density needed to advance the particle filter over an interval of pseudo time.

Clearly, it will not often be possible to derive closed form expressions for such an optimal flow. However, approximate methods may yield better filter performance than simply approximating the OID directly, for example with a Gaussian.



\subsection{Weight Updates, Importance and Artificial Target Densities}

Having chosen a flow, \eqref{eq:flow}, with which to move the particles, the next step is to use this to deduce the resulting proposal distribution and a suitable artificial conditional distribution with which to extend the target. We will examine two cases separately; the first where $\flowdiffuse{\pt}=0$, and the particles are moved entirely deterministically, and second case where $\flowdiffuse{\pt}\ne0$ and the particles move stochastically.

\subsubsection{Deterministic Flows}

When $\flowdiffuse{\pt}=0$, the stochastic differential equation \eqref{eq:flow} for particle motion collapses to an ordinary differential equation,
%
\begin{IEEEeqnarray}{rCl}
 \frac{d\ls{\pt}}{d\pt} & = & \flowdrift{\pt}(\ls{\pt})     .
\end{IEEEeqnarray}

In this case the particles are moved deterministically, meaning that the proposal density associated with an advance in pseudo-time from $\pt_0$ to $\pt_1$ collapses to a delta function. To find a valid formula for the weight update, we revert to the fundamental description of a particle weight as the ratio of target and importance probability measures. Thus, equation~\eqref{eq:general_weight_update} becomes,
%
\begin{IEEEeqnarray}{rCl}
  \pw{\rt,\pt_1}\pss{j} & = & \pw{\rt,\pt_0}\pss{j} \frac{ p(\ob{\rt} | \ls{\rt,\pt_1})^{\pt_1} p(d\ls{\rt,\pt_1} | \ls{\rt-1}) }{ p(\ob{\rt} | \ls{\rt,\pt_0})^{\pt_0} p(d\ls{\rt,\pt_0} | \ls{\rt-1}) } \times \frac{ \artden(d\ls{\rt,\pt_0} | \ls{\rt,\pt_1}) }{ q(d\ls{\rt,\pt_1}\pss{j} | \ls{\rt,\pt_0}\pss{j}) } \nonumber \\
  & = & \pw{\rt,\pt_0}\pss{j} \frac{ p(\ob{\rt} | \ls{\rt,\pt_1})^{\pt_1} p(\ls{\rt,\pt_1} | \ls{\rt-1}) }{ p(\ob{\rt} | \ls{\rt,\pt_0})^{\pt_0} p(\ls{\rt,\pt_0} | \ls{\rt-1}) } \times \magdet{ \frac{\partial \ls{\rt,\pt_1}}{\partial \ls{\rt,\pt_0}} } \times \frac{ \artden(d\ls{\rt,\pt_0} | \ls{\rt,\pt_1}) }{ q(d\ls{\rt,\pt_1}\pss{j} | \ls{\rt,\pt_0}\pss{j}) }    \label{eq:measure_weight_update}     .
\end{IEEEeqnarray}
%
For the importance measure, we select,
%
\begin{IEEEeqnarray}{rCl}
 \impden(d\ls{\rt,\pt_1}\pss{j} | \ls{\rt,\pt_0}\pss{j}) & = & \indic{ \flowmap{\pt_0}{\pt_1} (\ls{\rt,\pt_0}) }(d\ls{\rt,\pt_1})     ,
\end{IEEEeqnarray}
%
where the transport map is given by,
%
\begin{IEEEeqnarray}{rCl}
 \flowmap{\pt_0}{\pt_1} (\ls{\rt,\pt_0}) & = & \ls{\rt,\pt_0} + \int_{\pt_0}^{\pt_1} \flowdrift{\pt}(\ls{\rt,l}) d\ls{\rt,l}     .
\end{IEEEeqnarray}
%
An appropriate choice for the artificial conditional is a second indicator measure at the point given by the integral of the time-reversed flow,
%
\begin{IEEEeqnarray}{rCl}
 \artden(d\ls{\rt,\pt_1}\pss{j} | \ls{\rt,\pt_0}\pss{j}) & = & \indic{ \flowmap{\pt_1}{\pt_0} (\ls{\rt,\pt_1}) }(d\ls{\rt,\pt_0})     .
\end{IEEEeqnarray}
%
This results in a cancellation, and hence the following weight update equation,
%
\begin{IEEEeqnarray}{rCl}
 \pw{\rt,\pt_1}\pss{j} & = & \pw{\rt,\pt_0}\pss{j} \frac{ p(\ob{\rt} | \ls{\rt,\pt_1})^{\pt_1} p(\ls{\rt,\pt_1} | \ls{\rt-1}) }{ p(\ob{\rt} | \ls{\rt,\pt_0})^{\pt_0} p(\ls{\rt,\pt_0} | \ls{\rt-1}) } \times \magdet{ \frac{\partial \ls{\rt,\pt_1}}{\partial \ls{\rt,\pt_0}} }   \label{eq:deterministic_weight_update}     .
\end{IEEEeqnarray}



\subsubsection{Stochastic Flows}

When $\flowdiffuse{\pt}\ne0$, we can use \eqref{eq:general_weight_update} directly. The importance density is found by integrating the stochastic differential equation governing the flow \eqref{eq:flow} using the selected values of $\flowdrift{\pt}$ and $\flowdiffuse{\pt}$. The optimal choice for the artificial conditional density (in the sense of minimising the weight variance) is shown in \cite{DelMoral2006} to be,
%
\begin{IEEEeqnarray}{rCl}
 \artden(\ls{\rt,\pt_0}\pss{j} | \ls{\rt,\pt_1}\pss{j}) & = & \frac{ \oiden{\pt}(\ls{\rt,\pt_0} | \ls{\rt-1}) \impden(\ls{\rt,\pt_1} | \ls{\rt,\pt_0}) }{ \int \oiden{\pt}(\ls{\pt} | \ls{\rt-1}) \impden(\ls{\rt,\pt_1} | \ls{\rt,\pt}) d\ls{\pt} }     .
\end{IEEEeqnarray}



\section{The Linear Gaussian Model}

In order to implement an optimal form of the algorithm set out in the previous section, we need to achieve the following tasks:
\begin{itemize}
  \item Solve \eqref{eq:optimal_flow_PDE} to find the optimal choice for $\flowdrift{\pt}$.
  \item Select $\flowdiffuse{\pt}$ and hence use $\flowdrift{\pt}$ and $\flowdiffuse{\pt}$ to find the importance density, $\impden(\ls{\rt,\pt_1} | \ls{\rt,\pt_0})$.
  \item Calculate the optimal artificial conditional density, $\artden(\ls{\rt,\pt_0}\pss{j} | \ls{\rt,\pt_1}\pss{j})$ in the stochastic case, or the required Jacobian in the deterministic case.
\end{itemize}

These can all be performed analytically for a linear Gaussian model, specifically a model with a linear observation function and Gaussian transition and observation densities. The transition function need not be linear.
%
\begin{IEEEeqnarray}{rCl}
 p(\ls{\rt} | \ls{\rt-1}) & = & \normal{\ls{\rt}}{\transfun(\ls{\rt-1})}{\transcov} \nonumber \\
 p(\ob{\rt} | \ls{\rt})     & = & \normal{\ob{\rt}}{\obsmat \ls{\rt}}{\obscov}
\end{IEEEeqnarray}

This is the same model for which the OID can be calculated analytically, so using an SUPF here is largely redundant in practice. However, consideration of this model will lead us to a method for running a near-optimal SUPF for nonlinear non-Gaussian models.

Note that throughout this section, subscript $\rt$s are omitted for clarity on variables which vary with $\pt$.


\subsection{Optimal Deterministic Flow}

When $\flowdiffuse{\pt}=0$, an optimal flow is yielded by the following choice for $\flowdrift{\pt}$,
%
\begin{IEEEeqnarray}{rCl}
 \flowdrift{\pt}(\ls{\pt}) & = & \lfmat{\pt} \ls{\pt} + \lfshift{\pt},
\end{IEEEeqnarray}
%
where
%
\begin{IEEEeqnarray}{rCl}
 \lfmat{\pt} & = & - \frac{1}{2} \transcov \obsmat^T \left(\obscov + \pt \obsmat \transcov \obsmat^T \right)^{-1} \obsmat \\
 \lfshift{\pt} & = & \left[ I + 2 \pt \lfmat{\pt} \right] \left[ (I + \pt \lfmat{\pt}) \transcov \obsmat^T \obscov^{-1} \ob{\rt} + \lfmat{\pt} \transfun(\ls{\rt-1}) \right]     .
\end{IEEEeqnarray}
%
For proof, see Appendix~\ref{app:optimal_flow_linear_Gaussian}.

For this optimal choice of $\flowdrift{\pt}$, the map associated with a transition from $\pt_0$ to $\pt_1$ is,
%
\begin{IEEEeqnarray}{rCl}
 \flowmap{\pt_0}{\pt_1} (\ls{\rt,\pt_0}) & = & \lginterm{\pt_1}^{-\frac{1}{2}} \bigg[ \lginterm{\pt_0}^{\frac{1}{2}} \ls{\pt_0} \nonumber \\
  & & \qquad + \: \left( \lginterm{\pt_1}^{\frac{1}{2}} - \lginterm{\pt_0}^{\frac{1}{2}} \right) \obsmat^+ \ob{\rt} \nonumber \\
  & & \qquad - \: \left( \lginterm{\pt_1}^{-\frac{1}{2}} - \lginterm{\pt_0}^{-\frac{1}{2}} \right) \left( \obsmat^+ \ob{\rt} - \transfun(\ls{\rt-1}) \right) \bigg]     ,
\end{IEEEeqnarray}
%
where,
%
\begin{IEEEeqnarray}{rCl}
 \lginterm{\pt} & = & I + \pt \transcov \obsmat^T \obscov^{-1} \obsmat \nonumber     .
\end{IEEEeqnarray}
%
For proof see Appendix~\ref{app:optimal_map_linear_Gaussian}.

Finally, the Jacobian required for the weight update is given by,
%
\begin{IEEEeqnarray}{rCl}
 \magdet{ \frac{\partial \ls{\pt_1}}{\partial \ls{\pt_0}} } & = & \magdet{ \lginterm{\pt_1}^{-\frac{1}{2}} \lginterm{\pt_0}^{\frac{1}{2}} } \nonumber \\
 & = & \sqrt{ \frac{\magdet{\lginterm{\pt_0}}}{\magdet{\lginterm{\pt_1}}} }
\end{IEEEeqnarray}



\subsection{Optimal Stochastic Flow}

When $\flowdiffuse{\pt}\ne0$, the optimal choice for $\flowdrift{\pt}$ in the deterministic case is given by,
%
\begin{IEEEeqnarray}{rCl}
 \flowdrift{\pt}(\ls{\pt}) & = & \lfmat{D,\pt} \ls{\pt} + \lfshift{D,\pt},
\end{IEEEeqnarray}
%
where
%
\begin{IEEEeqnarray}{rCl}
 \lfmat{D,\pt} & = & \lfmat - \flowcov{\pt} \left[ \transcov^{-1} + \obsmat^T \obscov^{-1} \obsmat \right] \\
 \lfshift{D,\pt} & = & \lfshift + \flowcov{\pt} \left[ \transcov^{-1} \transfun(\ls{\rt-1}) + \pt \obsmat^T \obscov^{-1} \ob{\rt} \right]     .
\end{IEEEeqnarray}
%
For proof, see Appendix~\ref{app:optimal_flow_linear_Gaussian}.

A suitable choice of $\flowdiffuse{\pt}$ for this model is,
%
\begin{IEEEeqnarray}{rCl}
 \flowdiffuse{\pt} & = & \left[ \lfdiffsf \lgoicov{\pt} \right]^{\frac{1}{2}} \nonumber \\
                   & = & \left[ \lfdiffsf \left( \transcov^{-1} + \pt \obsmat^T \obscov^{-1} \obsmat \right) \right]^{\frac{1}{2}}     ,
\end{IEEEeqnarray}
%
where $\lfdiffsf$ is a positive scale factor. This choice encourages particles to diffuse faster in directions with a larger covariance and thus a larger uncertainty, which seems intuitively sensible.

For these choices of $\flowdrift{\pt}$ and $\flowdiffuse{\pt}$, the importance density associated with a transition form $\pt_0$ to $\pt_1$ is,
%
\begin{IEEEeqnarray}{rCl}
\impden(\ls{\pt_1} | \ls{\pt_0}) & = & \normal{\ls{\pt_1}}{\Gamma \ls{\pt_0} + \nu}{\Omega} \\
 \Gamma & = & \exp\left\{ -\frac{1}{2} \lfdiffsf \pt_1 \right\} \lginterm{\pt_1}^{-\frac{1}{2}} \lginterm{\pt_0}^{\frac{1}{2}} \nonumber \\
 \nu    & = & \exp\left\{ -\frac{1}{2} \lfdiffsf \pt_1 \right\} \lginterm{\pt_1}^{-\frac{1}{2}} \Bigg\{ \left[ \exp\left\{ \frac{1}{2} \lfdiffsf \pt_1 \right\} \lginterm{\pt_1}^{\frac{1}{2}} - \exp\left\{ \frac{1}{2} \lfdiffsf \pt_0 \right\} \lginterm{\pt_0}^{\frac{1}{2}} \right] \obsmat^+ \ob{\rt} \nonumber \\
 & & - \: \left[ \exp\left\{ \frac{1}{2} \lfdiffsf \pt_1 \right\} \lginterm{\pt_1}^{-\frac{1}{2}} - \exp\left\{ \frac{1}{2} \lfdiffsf \pt_0 \right\} \lginterm{\pt_0}^{-\frac{1}{2}} \right] \left( \obsmat^+ \ob{\rt} - \transfun(\ls{\rt-1}) \right) \Bigg\} \nonumber \\
 \Omega & = & \left[ 1 - \exp\left\{ - \lfdiffsf \left(\pt_1 - \pt_0\right) \right\} \right] \left(\transcov^{-1} + \pt_1 \obsmat^T \obscov^{-1} \obsmat\right)^{-1}
\end{IEEEeqnarray}
%
where,
%
\begin{IEEEeqnarray}{rCl}
 \lginterm{\pt} & = & I + \pt \transcov \obsmat^T \obscov^{-1} \obsmat \nonumber     .
\end{IEEEeqnarray}
%
For proof see Appendix~\ref{app:optimal_importance_density_linear_Gaussian}.

The optimal artificial density for this is given by the Kalman filter update equations,
%
\begin{IEEEeqnarray}{rCl}
 \artden(\ls{\pt_0} | \ls{\pt_1}) & = & \frac{ \oiden{\pt}(\ls{\pt_0} | \ls{\rt-1}) \impden(\ls{\pt_1} | \ls{\pt_0}) }{ \int \oiden{\pt}(\ls{\pt} | \ls{\rt-1}) \impden(\ls{\pt_1} | \ls{\pt}) d\ls{\pt} } \nonumber \\
 & \propto & \normal{\ls{\pt_0}}{\lgoimean{\pt_0}}{\lgoicov{\pt_0}} \normal{\ls{\pt_1}}{\Gamma \ls{\pt_0} + \nu}{\Omega} \nonumber \\
 & = & \normal{\ls{\pt_0}}{\lgoimean{\pt_0} + \lgoicov{\pt_0} \Gamma^T\left(\Gamma \lgoicov{\pt_0} \Gamma^T + \Omega\right)^{-1}\left(\ls{\pt_1} - \Gamma \lgoimean{\pt_0} - \nu \right)}{\lgoicov{\pt_0} - \lgoicov{\pt_0} \Gamma^T\left(\Gamma \lgoicov{\pt_0} \Gamma^T + \Omega\right)^{-1} \lgoicov{\pt_0}}     .
\end{IEEEeqnarray}
{\meta Betcha this simplifies. Also, that we can show that as $\lfdiffsf\rightarrow0$ then the stochastic case limits into the deterministic case.}



\subsection{Optimal SUPF for the Linear Gaussian Model}

Using the derived equations for the linear Gaussian model, an optimal SUPF algorithm can be implemented, as detailed in algorithm~\ref{}, using a single step to advance all the way through pseudo-time from $\pt=0$ to $\pt=1$.

{\meta Put a pseudo-code algorithm here.}



\section{Nonlinear Non-Gaussian Models}

So far, the only model considered is linear (in the observation function) and Gaussian. This is in fact not useful, since it is already possible to sample from the optimal importance distribution directly for this case, and the resulting weights may be calculated in closed form. However, we can now employ our analytical solutions for the flow in this nice case to approximate optimal flows for other models. Note the required approximations occur only in the choice of importance density. The resulting particle filter is therefore still ``exact'' in the asymptotic sense usual for particle filters, although only ``approximately optimal''.

\subsection{Linearisation}

As a first excursion into the realm of nonlinearities, consider the Gaussian model with nonlinear transition \emph{and} observation functions,
%
\begin{IEEEeqnarray}{rCl}
 p(\ls{\rt} | \ls{\rt-1}) & = & \normal{\ls{\rt}}{\transfun(\ls{\rt-1})}{\transcov} \nonumber \\
 p(\ob{\rt} | \ls{\rt})   & = & \normal{\ob{\rt}}{\obsfun(\ls{\rt})}{\obscov}     .
\end{IEEEeqnarray}

The observation model may be linearised in the usual way, by truncating the Taylor series expansion,
%
\begin{IEEEeqnarray}{rCl}
 \obsfun(\ls{}) & \approx & \obsfun(\ls{}^*) + \underbrace{\left.\frac{\partial \obsfun}{\partial \ls{}}\right|_{\ls{}^*}}_{\obsmat(\ls{}^*)} (\ls{} - \ls{}^*)
\end{IEEEeqnarray}
\begin{IEEEeqnarray}{rCl}
 p(\ob{\rt} | \ls{\rt}) & \approx & \normal{\linob{\rt}}{\obsmat(\ls{}^*)\ls{\rt}}{\obscov} \nonumber \\
 \linob{\rt}            & = & \ob{\rt} - \obsfun(\ls{}^*) + \obsmat(\ls{}^*)\ls{}^* \nonumber     ,
\end{IEEEeqnarray}
%
where $\ls{}^*$ is the point around which the function is linearised.

Rather than moving from $\pt=0$ to $\pt=1$, as was possible in the linear Gaussian case, we now advance through pseudo-time in small increments, using the current state as the linearisation point. By making a local, Gaussian approximation to the observation density, all the same formulas may be used for generating new states and updating weights as were used for the linear Gaussian model. If the pseudo-time step sizes are sufficiently small, such a method may well give better results than using an ordinary particle filter using a Gaussian approximation to the OID.



\subsection{Scale Mixtures of Normals}

A further generalisation is possible to heavy-tailed densities (either transition or observation) which may be represented as scale mixtures of normals,
%
\begin{IEEEeqnarray}{rCl}
 p(z) & = & \int \normal{z}{m}{\frac{1}{\xi}P} p(\xi) d\xi     .
\end{IEEEeqnarray}
%
For example, if $p(\xi)$ is a chi-square distribution (with $\nu$ degrees of freedom), then $p(z)$ is a student-t distribution (with $\nu$ degrees of freedom). With $1$ degree of freedom, this becomes a Cauchy distribution. Alpha-stable distributions may also be represented \cite{Godsill1999}.

By extending the target distribution to include the auxiliary mixing variable, $\xi$, the distribution becomes gamma-normal. We exploit this by sampling the mixing variable from its prior and then using the same optimal (or approximately optimal) flow methods for the linear (or nonlinear) Gaussian model. The importance density becomes simply,
%
\begin{IEEEeqnarray}{rCl}
 \impden(\ls{\pt_1} | \ls{\pt_0}, \xi) p(\xi)     ,
\end{IEEEeqnarray}
%
and the artificial conditional density,
%
\begin{IEEEeqnarray}{rCl}
 \artden(\ls{\pt_0} | \ls{\pt_1}, \xi) p(\xi)     ,
\end{IEEEeqnarray}
%
which results in no change to the weight update formulas.

In the same manner as the linearisation method for nonlinear models, the stretch of pseudo-time is divided into small intervals and the value for the mixing variable may be sampled afresh for each. This has the effect that each particle is updated according to a ``blend'' of different flows corresponding to different values of $\xi$, rather than a single value.

\subsection{Gradient Matching}

A cruder form of approximation is possible for densities which cannot be written as scale mixtures of normals. Again, the troublesome density is approximated by a Gaussian for short intervals of pseudo-time, but this time the Gaussian is chosen so as to have the same value and gradient as the true density at some particular point, $\ls{}^*$.

To match the transition density, we first write,
%
\begin{IEEEeqnarray}{rCl}
 \flowtd(\ls{}) & = & p(\ob{\rt} | \ls{\rt})     ,
\end{IEEEeqnarray}
%
and calculate $\flowtd(\ls{}^*)$ and $\Delta := \frac{\left. \nabla_{\ls{}} \flowtd \right|_{\ls{}^*}}{\flowtd(\ls{}^*)}$. Denoting the matched Gaussian density and its parameters with tildes, we can write the following,
%
\begin{IEEEeqnarray}{rCl}
 \tilde{\flowtd}(\ls{}) & := & \left| 2 \pi \tilde{\transcov} \right|^{-\frac{1}{2}} \exp\left\{ -\frac{1}{2} (\ls{}-\tilde{\transmean})^T \tilde{\transcov}^{-1} (\ls{}-\tilde{\transmean}) \right\} \nonumber \\
                   & = & \left| 2 \pi \tilde{\transcov} \right|^{-\frac{1}{2}} \exp\left\{ -\frac{1}{2} \tilde{\Delta}^T \tilde{\transcov} \tilde{\Delta} \right\} \nonumber \\
 \tilde{\Delta} := \frac{\left.\nabla_{\ls{}} \tilde{\flowtd}(\ls{})\right|_{\ls{}^*}}{\tilde{\flowtd}(\ls{})} & = & - \tilde{\transcov}^{-1} (\ls{}-\tilde{\transmean}) \nonumber      .
\end{IEEEeqnarray}
%
Now equating $\flowtd(\ls{}^*)=\tilde{\flowtd}(\ls{}^*)$ and $\Delta=\tilde{\Delta}$, and selecting $\tilde{\transcov} = \tilde{\sigma}_P^2 I$, we have,
%
\begin{IEEEeqnarray}{rCl}
 \flowtd(\ls{}^*) & = & (2 \pi \tilde{\sigma}_P^2)^{\frac{-d_S}{2}} \exp \left\{ -\frac{1}{2} \left|\Delta\right|^2 \tilde{\sigma}_P^2 \right\} \nonumber
\end{IEEEeqnarray}
%
and thus the parameters of the matched Gaussian are given by,
%
\begin{IEEEeqnarray}{rCl}
 \tilde{\transcov}  & = & \tilde{\sigma}_P^2 I \nonumber \\
 \tilde{\sigma}_P^2 & = & \frac{d_S}{\left|\Delta\right|^2} \W\left[ \frac{\left|\Delta\right|^2}{2 \pi d_S} \flowtd(\ls{}^*)^{-\frac{2}{d_S}} \right] \nonumber \\
 \tilde{\transmean} & = & \ls{}^* + \tilde{\sigma}_P^2 \Delta     ,
\end{IEEEeqnarray}
%
where $\W$ is the Lambert-W or product-log function and $d_S$ is the number of state dimensions.

Repeating the same process for the observation density,
%
\begin{IEEEeqnarray}{rCl}
 \flowod(\ls{}) & = & p(\ob{\rt} | \ls{}) \nonumber \\
 \Delta & := & \frac{\left. \nabla_{\ls{}} \flowod \right|_{\ls{}^*}}{\flowod(\ls{}^*)} \nonumber     ,
\end{IEEEeqnarray}
%
with the additional step that we assume $\tilde{\obsmat}=I$, we obtain,
%
\begin{IEEEeqnarray}{rCl}
 \tilde{\flowod}(\ls{}) & := & \left| 2 \pi \tilde{\obscov} \right|^{-\frac{1}{2}} \exp\left\{ -\frac{1}{2} (\tilde{y} - \tilde{\obsmat} \ls{})^T \tilde{\obscov}^{-1} (\tilde{y} - \tilde{\obsmat} \ls{}) \right\} \nonumber \\
 \tilde{\obsmat} & = & I \nonumber \\
 \tilde{\obscov} & = & \tilde{\sigma}_L^2 I \nonumber \\
 \tilde{\sigma}_L^2 & = & \frac{d_S}{\left|\Delta\right|^2} \W\left[ \frac{\left|\Delta\right|^2}{2 \pi d_S} \flowod(\ls{}^*)^{-\frac{2}{d_S}} \right] \nonumber \\
 \tilde{y} & = & \ls{}^* + \tilde{\sigma}_L^2 \Delta     .
\end{IEEEeqnarray}

Other methods of matching are possible, for example choosing the Gaussian with the same gradient and Hessian as the true density. This requires special handling when the Hessian is not positive definite.



\subsection{Approximately Optimal SUPF for Nonlinear Non-Gaussian Models}

For nonlinear or non-Gaussian models, the SUPF is still an exact particle filter, but is only approximately optimal. Unlike the linear-Gaussian case, it is necessary to divide up pseudo-time into short intervals and make use of one of the Gaussian approximations for each interval. A summary is shown in algorithm~\ref{}.

{\meta Put another pseudo-code algorithm here.}



\section{Numerical Simulations}
\subsection{A Linear Gaussian Model}
\subsection{A Nonlinear Model}
\subsubsection{Gaussian Noise}
\subsubsection{Student-t Noise}





\section{OLD STUFF}


\subsection{Intermediate Resampling}

As the filter advances through the interval of pseudo-time, it may become apparent long before $\pt$ approaches $1$ that some particles are going to have very low weights and are highly unlikely to be selected for the next time step. This motivates the introduction of intermediate resampling during the pseudo-time interval. The effective sample size can be calculated after each step in the numerical integration and resampling conducted whenever this falls below a chosen threshold. In this way, we ensure that a diverse particle collection is maintained, and computation is not wasted in performing numerical integration for insignificant particles.

Resampling steps introduce correlation between particles which will decay over time. The rate of this decay is determined by the diffusion term $\glam$. In the limit, when $\glam=0$, and the flow is deterministic, multiple copies of the same particle will remain identical until $\pt=1$. Note that the resampling is still beneficial as it means we do not waste computation on useless particles. On the other hand, when the $\glam$ is large, the particles will rapidly de-correlate after resampling, but smaller step sizes will be required in the numerical integration.



\section{Further Extensions}

\subsection{Mixed States}

The methods considered in the previous sections are applicable only to continuous state spaces. However, mixed state spaces can be handled easily by proposing the discrete portion of the state and then using a smooth update for the continuous part.

{\meta It would be nice to be able to include discrete states in the flow, with some sort of stochastic switching. In effect, have a continuous time Markov chain in parallel with the SDE. I've looked at this, but without much success yet.}

\subsection{Intermittent Observations}

It is commonly the case that an observation is not received at every time step.

{\meta Handle this by concatenating all the intervening states. This needs further thought and testing.}



\section{Numerical Demonstrations}

In this section, we demonstrate the effectiveness of the SUPF on a number of simulations.

\subsection{Linear Gaussian Model}

We first consider the simplest example, in which the transition and observation models are linear and Gaussian,
%
\begin{IEEEeqnarray}{rCl}
 p(\ls{\rt} | \ls{\rt-1}) & = & \mathcal{N}(\ls{\rt}|F \ls{\rt-1},Q) \nonumber \\
 p(\ob{\rt} | \ls{\rt})     & = & \mathcal{N}(\ob{\rt}|H \ls{\rt}    ,R)      .
\end{IEEEeqnarray}

For the SUPF, we can use the optimal flow derived for linear Gaussian models. However, we can also run an ordinary particle filter which samples exactly from the OID. The SUPF would, therefore, never be used in practice for this example. We include it simply to demonstrate that the particles approximations it generates are as good as the optimal choice.

The model parameters are as follows:

{\meta END OF OLD STUFF}






\appendix

\section{Governing Equation for the Optimal Flow} \label{app:optimal_flow_governing_eq}

This derivation is based closely on the exposition of \cite{Daum2008}, but we consider moving each particle according to its OID sequence rather than the filtering distribution. We omit the time subscripts, particle superscripts and the dependence on $\ls{\rt-1}$ for clarity. In addition, the transition and observation densities are written as,
%
\begin{IEEEeqnarray}{rCl}
 \flowtd(\ls{}) & = & p(\ls{}|\ls{\rt-1}) \nonumber \\
 \flowod(\ls{}) & = & p(\ob{\rt}|\ls{}) \nonumber      .
\end{IEEEeqnarray}

An equation for the optimal flow may be derived by considering the sequence of densities, $\oiden{\pt}(\ls{\pt})$. Taking the log and differentiating with respect to $\pt$ and $\ls{\pt}$,
%
\begin{IEEEeqnarray}{rCl}
 \log\left( \oiden{\pt}(\ls{\pt}) \right) & = & \log\left( \flowtd(\ls{\pt}) \right) + \pt \log\left( \flowod(\ls{\pt}) \right) - \log\left(\oinorm{\pt}\right)     ,
\end{IEEEeqnarray}
%
\begin{IEEEeqnarray}{rCl}
 \frac{\partial}{\partial \pt} \log\left( \oiden{\pt}(\ls{\pt}) \right) & = & \frac{ 1 }{ \oiden{\pt}(\ls{\pt}) } \frac{\partial \oiden{\pt}}{\partial \pt} \nonumber \\
  & = & \log\left(\flowod(\ls{\pt})\right) - \frac{d}{d\pt}\log\left(\oinorm{\pt}\right) \label{eq:dpi-dlam}     ,
\end{IEEEeqnarray}
%
\begin{IEEEeqnarray}{rCl}
 \nabla \log\left( \oiden{\pt}(\ls{\pt}) \right) & = & \frac{ 1 }{ \oiden{\pt}(\ls{\pt}) } \nabla \oiden{\pt}(\ls{\pt}) \label{eq:dpi-dx}     .
\end{IEEEeqnarray}
%
The Fokker-Planck equation relates the flow of a particle with the evolution of the density for its position. For a particle moving according to,
%
\begin{IEEEeqnarray}{rCl}
 d\ls{\pt} & = & \flowdrift{\pt}(\ls{\pt}) d\pt + \flowdiffuse{\pt} d\flowbm{\pt}     ,
\end{IEEEeqnarray}
%
Fokker-Planck states,
%
\begin{IEEEeqnarray}{rCl}
 \frac{\partial \oiden{\pt}}{\partial \pt} & = & - \nabla \cdot \left[ \flowdrift{\pt}(\ls{\pt}) \oiden{\pt}(\ls{\pt}) \right] + \nabla \cdot \left[ \flowcov{\pt} \nabla \oiden{\pt}(\ls{\pt}) \right]     .
\end{IEEEeqnarray}
%
Substituting \eqref{eq:dpi-dlam} and \eqref{eq:dpi-dx}, we have,
%
\begin{IEEEeqnarray}{rCl}
 \frac{\partial \oiden{\pt}}{\partial \pt} & = & -\nabla \cdot \left[ \flowdrift{\pt}(\ls{\pt}) \oiden{\pt}(\ls{\pt}) \right] + \nabla \cdot \left[ \flowcov{\pt} \nabla \oiden{\pt}(\ls{\pt}) \right]     \nonumber \\
 \oiden{\pt}(\ls{\pt}) \left[ \log\left(\flowod(\ls{\pt})\right) - \frac{d}{d\pt}\log\left(\oinorm{\pt}\right) \right] & = & -\nabla\cdot \flowdrift{\pt}(\ls{\pt}) \oiden{\pt}(\ls{\pt}) - \flowdrift{\pt}(\ls{\pt}) \cdot \nabla \oiden{\pt}(\ls{\pt}) + \nabla \cdot \left[ \flowcov{\pt} \nabla \oiden{\pt}(\ls{\pt}) \right] \nonumber \\
 \left[ \log\left(\flowod(\ls{\pt})\right) - \frac{d}{d\pt}\log\left(\oinorm{\pt}\right) \right] & = & -\nabla\cdot \flowdrift{\pt}(\ls{\pt}) - \flowdrift{\pt}(\ls{\pt}) \cdot \nabla \log\left( \oiden{\pt}(\ls{\pt}) \right) + \frac{ 1 }{ \oiden{\pt}(\ls{\pt}) } \nabla \cdot \left[ \flowcov{\pt} \nabla \oiden{\pt}(\ls{\pt}) \right]      .
\end{IEEEeqnarray}
%
where in the last step we have divided through by $\oiden{\pt}$. This requires the density to be nowhere vanishing. Finally consider the normalising constant,
%
\begin{IEEEeqnarray}{rCl}
 \frac{d}{d\pt}\log\left(\oinorm{\pt}\right) & = & \frac{\frac{d\oinorm{\pt}}{d\pt}}{\oinorm{\pt}} \nonumber \\
                                               & = & \frac{ \int \flowtd(\ls{\pt}) \flowod(\ls{\pt})^\pt \log\left(\flowod(\ls{\pt})\right) d\ls{\rt} }{ \int \flowtd(\ls{\pt}) \flowod(\ls{\pt})^\pt d\ls{\pt} } \nonumber \\
                                               & = & \expect{\oiden{\pt}}\left[ \log\left(\flowod(\ls{\pt})\right) \right]     .
\end{IEEEeqnarray}
%
Thus,
%
\begin{IEEEeqnarray}{rCl}
 \log\left(\flowod(\ls{\pt})\right) - \expect{\oiden{\pt}}\left[ \log\left(\flowod(\ls{\pt})\right) \right] & = & -\nabla\cdot \flowdrift{\pt}(\ls{\pt}) - \flowdrift{\pt}(\ls{\pt}) \cdot \nabla \log\left( \oiden{\pt}(\ls{\pt}) \right) + \frac{ 1 }{ \oiden{\pt}(\ls{\pt}) } \nabla \cdot \left[ \flowcov{\pt} \nabla \oiden{\pt}(\ls{\pt}) \right] \label{app-eq:optimal_flow_PDE}      .
\end{IEEEeqnarray}

The result is a partial differential equation (PDE), for which any solution, $\flowdrift{\pt}$ and $\flowdiffuse{\pt}$, will produce an optimal flow, which maps particles sampled from the prior (i.e. the transition density) to new locations distributed according to the OID.



\section{Optimal Flow for a Linear Gaussian Model} \label{app:optimal_flow_linear_Gaussian}

If the transition and observation densities are Gaussian, and the observation function is linear, then the optimal flow PDE can be solved analytically. Time subscripts, particle superscripts and dependence on $\ls{\rt-1}$ is omitted where appropriate for clarity. In addition, the transition and observation densities are written as,
%
\begin{IEEEeqnarray}{rCcCl}
 \flowtd(\ls{}) & = & p(\ls{} | \ls{\rt-1}) & = & \normal{\ls{}}{\transmean}{\transcov} \nonumber \\
 \flowod(\ls{}) & = & p(\ob{\rt} | \ls{})   & = & \normal{\ob{\rt}}{\obsmat \ls{}}{\obscov} \nonumber \\
 \transmean & = & \transfun(\ls{\rt-1}) \nonumber
\end{IEEEeqnarray}
%
For this model, the OID for pseudo-time $\pt$ is available analytically,
%
\begin{IEEEeqnarray}{rCl}
 \oiden{\pt}(\ls{\pt}) & = & \mathcal{N}(\ls{\pt}|\lgoimean{\pt},\lgoicov{\pt}) \nonumber    ,
\end{IEEEeqnarray}
%
where
%
\begin{IEEEeqnarray}{rCl}
 \lgoicov{\pt} & = & \left[ \transcov^{-1} + \obsmat^T \left(\frac{\obscov}{\pt}\right)^{-1} \obsmat \right]^{-1} \nonumber \\
 \lgoimean{\pt}    & = & \lgoicov{\pt} \left[ \transcov^{-1} \transmean + \obsmat^T \left(\frac{\obscov}{\pt}\right)^{-1} \ob{\rt} \right] \nonumber     .
\end{IEEEeqnarray}
%
The following intermediate terms can then be calculated,
%
\begin{IEEEeqnarray}{rCl}
 \log\left(\flowtd(\ls{\pt})\right) & = & -\frac{1}{2}\log\left(\left| 2 \pi \transcov \right|\right) - \frac{1}{2}(\ls{\pt}-\transmean)^T \transcov^{-1}( \ls{\pt}-\transmean) \nonumber \\
 \log\left(\flowod(\ls{\pt})\right) & = & -\frac{1}{2}\log\left(\left| 2 \pi \obscov   \right|\right) - \frac{1}{2}(\ob{\rt}-\obsmat\ls{\pt})^T \obscov^{-1}(\ob{\rt}-\obsmat\ls{\pt}) \nonumber \\
 \nabla \log\left(\flowtd(\ls{\pt})\right) & = & -\transcov^{-1}(\ls{\pt}-\transmean) \nonumber \\
 \nabla \log\left(\flowod(\ls{\pt})\right)  & = & \obsmat^T \obscov^{-1}(\ob{\rt}-\obsmat\ls{\pt}) \nonumber \\
 \nabla \log\left(\oiden{\pt}(\ls{\pt})\right)  & = & \left[ -\transcov^{-1}(\ls{\pt}-\transmean) + \pt \obsmat^T \obscov^{-1}(\ob{\rt}-\obsmat\ls{\pt}) \right] \nonumber \\
                                         & = & - \lgoicov{\pt}^{-1} \left(\ls{\pt}-\lgoimean{\pt}\right) \nonumber \\
 \expect{\oiden{\pt}}\left[ \log\left(\flowod(\ls{\pt})\right) \right] & = & -\frac{1}{2}\log\left(\left| 2 \pi \obscov \right|\right) - \frac{1}{2} \expect{\oiden{\pt}}\left[ (\ob{\rt}-\obsmat\ls{\pt})^T \obscov^{-1}(\ob{\rt}-\obsmat\ls{\pt}) \right] \nonumber \\
 \expect{\oiden{\pt}}\left[ (\ob{\rt}-\obsmat\ls{\pt})^T \obscov^{-1}(\ob{\rt}-\obsmat\ls{\pt}) \right] & = & \ob{\rt}^T \obscov^{-1} \ob{\rt} - 2 \ob{\rt}^T \obscov^{-1} \obsmat \lgoimean{\pt} + \lgoimean{\pt}^T \obsmat^T \obscov^{-1} \obsmat \lgoimean{\pt} + \trace\left( \obsmat^T \obscov^{-1} \obsmat \lgoicov{\pt} \right) \nonumber
\end{IEEEeqnarray}

\subsection{Deterministic Case}

Assume the flow takes the form,
%
\begin{IEEEeqnarray}{rCl}
 \flowdrift{\pt}(\ls{\pt}) & = & \lfmat{\pt} \ls{\pt} + \lfshift{\pt} \label{app-eq:linear_drift}     .
\end{IEEEeqnarray}

Substituting terms into \eqref{app-eq:optimal_flow_PDE} and using $\flowcov{\pt}=0$ gives us an equation for the the deterministic case,
%
\begin{IEEEeqnarray}{rCl}
\IEEEeqnarraymulticol{3}{l}{ -\frac{1}{2}(\ob{\rt}-\obsmat\ls{\pt})^T \obscov^{-1}(\ob{\rt}-\obsmat\ls{\pt}) + \frac{1}{2}\expect{\pi}\left[ (\ob{\rt}-\obsmat\ls{\pt})^T \obscov^{-1}(\ob{\rt}-\obsmat\ls{\pt}) \right] } \nonumber \\
 \qquad & = & - \trace(\lfmat{\pt}) + \left( \lfmat{\pt} \ls{\pt} + \lfshift{\pt} \right)^T \lgoicov{\pt}^{-1} \left(\ls{\pt}-\lgoimean{\pt}\right) \nonumber \\
\IEEEeqnarraymulticol{3}{l}{ \ob{\rt}^T \obscov^{-1} \obsmat (\ls{\pt} - \lgoimean{\pt}) + \frac{1}{2}\left[ \lgoimean{\pt}^T \obsmat^T \obscov^{-1} \obsmat \lgoimean{\pt} + \trace\left( \obsmat^T \obscov^{-1} \obsmat \lgoicov{\pt} \right) - \ls{\pt}^T \obsmat^T \obscov^{-1} \obsmat \ls{\pt} \right] } \nonumber \\
 \qquad & = & - \trace(\lfmat{\pt}) + \left( \lfmat{\pt} \ls{\pt} + \lfshift{\pt} \right)^T \lgoicov{\pt}^{-1} \left(\ls{\pt}-\lgoimean{\pt}\right)      .
\end{IEEEeqnarray}
%
Now equating terms gives us the following equations, which allow us to find values of $\lfmat{\pt}$ and $\lfshift{\pt}$,
%
\begin{IEEEeqnarray}{rCl}
 - \frac{1}{2} \obsmat^T \obscov^{-1} \obsmat & = & \lfmat{\pt}^T \lgoicov{\pt}^{-1} \nonumber \\
 \lfmat{\pt} & = & - \frac{1}{2} \lgoicov{\pt} \obsmat^T \obscov^{-1} \obsmat \nonumber \\
            & = & - \frac{1}{2} \left[ \transcov - \transcov \obsmat^T \left(\left(\frac{\obscov}{\pt}\right) + \obsmat \transcov \obsmat^T \right)^{-1} \obsmat \transcov \right] \obsmat^T \obscov^{-1} \obsmat \nonumber \\
            & = & - \frac{1}{2} \transcov \obsmat^T \left[ \obscov^{-1} - \left(\left(\frac{\obscov}{\pt}\right) + \obsmat \transcov \obsmat^T \right)^{-1} \obsmat \transcov \obsmat^T \obscov^{-1} \right] \obsmat \nonumber \\
            & = & - \frac{1}{2} \transcov \obsmat^T \left(\left(\frac{\obscov}{\pt}\right) + \obsmat \transcov \obsmat^T \right)^{-1} \underbrace{\left[ \left(\left(\frac{\obscov}{\pt}\right) + \obsmat \transcov \obsmat^T \right) \obscov^{-1} - \obsmat \transcov \obsmat^T \obscov^{-1} \right]}_{\frac{1}{\pt} I} \obsmat \nonumber \\
            & = & - \frac{1}{2} \transcov \obsmat^T \left(\obscov + \pt \obsmat \transcov \obsmat^T \right)^{-1} \obsmat     .
\end{IEEEeqnarray}
%
\begin{IEEEeqnarray}{rCl}
 \ob{\rt}^T \obscov^{-1} \obsmat  & = & \lfshift{\pt}^T \lgoicov{\pt}^{-1} - \lgoimean{\pt}^T \lgoicov{\pt}^{-1} \lfmat{\pt} \nonumber \\
 \lfshift{\pt} & = & \lgoicov{\pt} \left[ \obsmat^T \obscov^{-1} \ob{\rt} + \lfmat{\pt}^T \lgoicov{\pt}^{-1} \lgoimean{\pt} \right] \label{app-eq:lG_shift_basic} \\
            & = & \left[ \transcov^{-1} + \pt \obsmat^T \obscov^{-1} \obsmat \right]^{-1} \left[ \obsmat^T \obscov^{-1} \ob{\rt} + \pt \lfmat{\pt}^T \obsmat^T \obscov^{-1} \ob{\rt} + \lfmat{\pt}^T \transcov^{-1} \transmean \right] \nonumber \\
            & = & \left[ \transcov - \transcov \obsmat^T \left(\left(\frac{\obscov}{\pt}\right) + \obsmat \transcov \obsmat^T \right)^{-1} \obsmat \transcov \right] \left[ (I + \pt \lfmat{\pt}^T) \obsmat^T \obscov^{-1} \ob{\rt} + \lfmat{\pt}^T \transcov^{-1} \transmean \right] \nonumber \\
            & = & \left[ I + 2 \pt \lfmat{\pt} \right] \transcov \left[ (I + \pt \lfmat{\pt}^T) \obsmat^T \obscov^{-1} \ob{\rt} + \lfmat{\pt}^T \transcov^{-1} \transmean \right] \nonumber \\
            & = & \left[ I + 2 \pt \lfmat{\pt} \right] \left[ (I + \pt \lfmat{\pt}) \transcov \obsmat^T \obscov^{-1} \ob{\rt} + \lfmat{\pt} \transmean \right]     ,
\end{IEEEeqnarray}
%
where we have used $\transcov \lfmat{\pt}^T = \lfmat{\pt} \transcov$ in the last line. Finally we need to make sure the constant terms balance,
%
\begin{IEEEeqnarray}{rCl}
 \IEEEeqnarraymulticol{3}{l}{-\ob{\rt}^T \obscov^{-1} \obsmat \lgoimean{\pt} + \frac{1}{2} \lgoimean{\pt}^T \obsmat^T \obscov^{-1} \obsmat \lgoimean{\pt} + \frac{1}{2} \trace\left( \obsmat^T \obscov^{-1} \obsmat \lgoicov{\pt} \right)} \nonumber \\
 \qquad \qquad \qquad & = & - \trace(\lfmat{\pt}) + \lfshift{\pt}^T \lgoicov{\pt}^{-1} \lgoimean{\pt}     .
\end{IEEEeqnarray}
%
Comparing the trace terms using the formula for $\lfmat{\pt}$,
%
\begin{IEEEeqnarray}{rCl}
 \text{RHS} & = & - \trace(\lfmat{\pt}) \nonumber \\
            & = & \frac{1}{2} \trace\left( \lgoicov{\pt} \obsmat^T \obscov^{-1} \obsmat \right) \nonumber \\
            & = & \frac{1}{2} \trace\left( \obsmat^T \obscov^{-1} \obsmat \lgoicov{\pt} \right) \nonumber \\
            & = & \text{LHS}     .
\end{IEEEeqnarray}
%
Examining the remaining terms using the formula for $\lfshift{\pt}$ and $\lfmat{\pt}$,
%
\begin{IEEEeqnarray}{rCl}
 \text{RHS} & = & - \lfshift{\pt}^T \lgoicov{\pt}^{-1} \lgoimean{\pt} \nonumber \\
            & = & - \left[ \obsmat^T \obscov^{-1} \ob{\rt} + \lfmat{\pt}^T \lgoicov{\pt}^{-1} \lgoimean{\pt} \right]^T \lgoimean{\pt} \nonumber \\
            & = & - \left[ \obsmat^T \obscov^{-1} \ob{\rt} - \frac{1}{2} \obsmat^T \obscov^{-1} \obsmat \lgoimean{\pt} \right]^T \lgoimean{\pt} \nonumber \\
            & = & -\ob{\rt}^T \obscov^{-1} \obsmat \lgoimean{\pt} + \frac{1}{2} \lgoimean{\pt}^T \obsmat^T \obscov^{-1} \obsmat \lgoimean{\pt} \nonumber \\
            & = & \text{LHS}     .
\end{IEEEeqnarray}
%
Hence the assumed form \eqref{app-eq:linear_drift} for the drift is valid with the derived values.

\subsection{Stochastic Case}

If $\flowcov{\pt}\ne0$, then we must consider the additional intermediate terms,
%
\begin{IEEEeqnarray}{rCl}
 \nabla \oiden{\pt}(\ls{\pt}) & = & \oiden{\pt}(\ls{\pt}) \left[ -\lgoicov{\pt}^{-1} \left(\ls{\pt}-\lgoimean{\pt}\right) \right] \\
 \nabla \cdot \left[ \flowcov{\pt} \nabla \oiden{\pt}(\ls{\pt}) \right] & = & \nabla \cdot \left\{ \oiden{\pt}(\ls{\pt}) \left[ - \flowcov{\pt} \lgoicov{\pt}^{-1} \left(\ls{\pt}-\lgoimean{\pt}\right) \right] \right\} \nonumber \\
 & = & \nabla \oiden{\pt}(\ls{\pt}) \cdot \left[ - \flowcov{\pt} \lgoicov{\pt}^{-1} \left(\ls{\pt}-\lgoimean{\pt}\right) \right] + \oiden{\pt}(\ls{\pt}) \nabla \cdot \left[ - \flowcov{\pt} \lgoicov{\pt}^{-1} \left(\ls{\pt}-\lgoimean{\pt}\right) \right] \nonumber \\
 & = & \oiden{\pt}(\ls{\pt}) \left\{ \left(x-\mu_{\pt}\right)^T \lgoicov{\pt}^{-1} \flowcov{\pt} \lgoicov{\pt}^{-1} \left(\ls{\pt}-\lgoimean{\pt}\right) - \trace\left[ \flowcov{\pt} \lgoicov{\pt}^{-1} \right] \right\}     .
\end{IEEEeqnarray}

If we again assume that the drift depends linearly on $\ls{\pt}$,
%
\begin{IEEEeqnarray}{rCl}
 \flowdrift{\pt}(\ls{\pt}) & = & \lfmat{D,\pt} \ls{\pt} + \lfshift{D,\pt}     ,
\end{IEEEeqnarray}
%
then we can find $\lfmat{D,\pt}$ and $\lfshift{D,\pt}$ by equating terms again. For $\lfmat{D,\pt}$,
%
\begin{IEEEeqnarray}{rCl}
 - \frac{1}{2} \obsmat^T \obscov^{-1} \obsmat & = & \lfmat{D,\pt}^T \lgoicov{\pt}^{-1} + \lgoicov{\pt}^{-1} \flowcov{\pt} \lgoicov{\pt}^{-1} \nonumber \\
 \lfmat{D,\pt} & = & - \frac{1}{2} \lgoicov{\pt} \obsmat^T \obscov^{-1} \obsmat - \flowcov{\pt} \lgoicov{\pt}^{-1} \nonumber \\
              & = & \lfmat{\pt} - \flowcov{\pt} \lgoicov{\pt}^{-1}      .
\end{IEEEeqnarray}
%
For $\lfshift{D,\pt}$,
%
\begin{IEEEeqnarray}{rCl}
 \ob{\rt}^T \obscov^{-1} \obsmat  & = & \lfshift{D,\pt}^T \lgoicov{\pt}^{-1} - \lgoimean{\pt}^T \lgoicov{\pt}^{-1} \lfmat{D,\pt} - 2 \lgoimean{\pt}^T \lgoicov{\pt}^{-1} \flowcov{\pt} \lgoicov{\pt}^{-1} \nonumber \\
 \lfshift{D,\pt} & = & \lgoicov{\pt} \left[ \obsmat^T \obscov^{-1} \ob{\rt} + \lfmat{D,\pt}^T \lgoicov{\pt}^{-1} \lgoimean{\pt} \right] + 2 \flowcov{\pt} \lgoicov{\pt}^{-1} \lgoimean{\pt} \nonumber \\
              & = & \lgoicov{\pt} \left[ \obsmat^T \obscov^{-1} \ob{\rt} + \lfmat{\pt}^T \lgoicov{\pt}^{-1} \lgoimean{\pt} \right] + \flowcov{\pt} \lgoicov{\pt}^{-1} \lgoimean{\pt} \nonumber \\
            & = & \lfshift{\pt} + \flowcov{\pt} \lgoicov{\pt}^{-1} \lgoimean{\pt} \nonumber \\
            & = & \lfshift{\pt} + \flowcov{\pt} \left[ \transcov^{-1} \transmean + \pt \obsmat^T \obscov^{-1} \ob{\rt} \right] \label{app-eq:lg_shift_stochastic}     .
\end{IEEEeqnarray}

Finally, we need to check again that the constant terms balance.
%
\begin{IEEEeqnarray}{rCl}
 \text{RHS} & = & - \trace(\lfmat{D,\pt}) - \trace\left( \flowcov{\pt} \lgoicov{\pt}^{-1} \right) \nonumber \\
            & = & - \trace\left( \lfmat{D,\pt} + \flowcov{\pt} \lgoicov{\pt}^{-1} \right) \nonumber \\
            & = & \trace\left( \lfmat{\pt} \right) \nonumber \\
            & = & \frac{1}{2} \trace\left( \lgoicov{\pt} \obsmat^T \obscov^{-1} \obsmat \right) \nonumber \\
            & = & \frac{1}{2} \trace\left( \obsmat^T \obscov^{-1} \obsmat \lgoicov{\pt} \right)      .
\end{IEEEeqnarray}
%
\begin{IEEEeqnarray}{rCl}
 \text{RHS} & = & - \lfshift{D,\pt}^T \lgoicov{\pt}^{-1} \lgoimean{\pt} + \lgoimean{\pt}^T \lgoicov{\pt}^{-1} \flowcov{\pt} \lgoicov{\pt}^{-1} \lgoimean{\pt} \nonumber \\
            & = & - \left[  \lfshift{\pt} + 2 \flowcov{\pt} \lgoicov{\pt}^{-1} \lgoimean{\pt} \right]^T \lgoicov{\pt}^{-1} \lgoimean{\pt} + \lgoimean{\pt}^T \lgoicov{\pt}^{-1} \flowcov{\pt} \lgoicov{\pt}^{-1} \lgoimean{\pt} \nonumber \\
            & = & - \lfshift{\pt}^T \lgoicov{\pt}^{-1} \lgoimean{\pt} - \lgoimean{\pt}^T \lgoicov{\pt}^{-1} \flowcov{\pt} \lgoicov{\pt}^{-1} \lgoimean{\pt} \nonumber \\
            & = & - \left[ \obsmat^T \obscov^{-1} \ob{\rt} + \lfmat{D,\pt}^T \lgoicov{\pt}^{-1} \lgoimean{\pt} \right]^T \lgoimean{\pt} - \lgoimean{\pt}^T \lgoicov{\pt}^{-1} \flowcov{\pt} \lgoicov{\pt}^{-1} \lgoimean{\pt} \nonumber \\
            & = & - \left[ \obsmat^T \obscov^{-1} \ob{\rt} - \frac{1}{2} \obsmat^T \obscov^{-1} \obsmat \lgoimean{\pt} - \lgoicov{\pt}^{-1}\flowcov{\pt}\lgoicov{\pt}^{-1}\lgoimean{\pt} \right]^T \lgoimean{\pt} - \lgoimean{\pt}^T \lgoicov{\pt}^{-1} \flowcov{\pt} \lgoicov{\pt}^{-1} \lgoimean{\pt} \nonumber \\
            & = & -\ob{\rt}^T \obscov^{-1} \obsmat \lgoimean{\pt} + \frac{1}{2} \lgoimean{\pt}^T \obsmat^T \obscov^{-1} \obsmat \lgoimean{\pt} \nonumber \\
            & = & \text{LHS}     .
\end{IEEEeqnarray}



\section{Optimal Deterministic Transport Map for a Linear Gaussian Model} \label{app:optimal_map_linear_Gaussian}

We require the transport map,
%
\begin{IEEEeqnarray}{rCl}
 \ls{\pt_1} = \flowmap{\pt_0}{\pt_1} (\ls{\rt,\pt_0}) & = & \ls{\rt,\pt_0} + \int_{\pt_0}^{\pt_1} \flowdrift{\pt}(\ls{\rt,l}) d\ls{\rt,l} \nonumber     ,
\end{IEEEeqnarray}
%
for the optimal, deterministic flow associated with a linear Gaussian model,
%
\begin{IEEEeqnarray}{rCl}
 \frac{d\ls{\pt}}{d\pt} & = & \flowdrift{\pt}(\ls{\pt}) \nonumber \\
                        & = & \lfmat{\pt} \ls{\pt} + \lfshift{\pt} \label{app-eq:deterministic_lG_ODE}      .
\end{IEEEeqnarray}
%
This linear, matrix differential equation may be solved using the integrating factor method. First define,
%
\begin{IEEEeqnarray}{rCl}
 P_{\pt} & = & - \int_{\pt_0}^{\pt_1} \lfmat{l} dl \nonumber \\
 M_{\pt} & = & \exp\left\{ P_{\pt} \right\} \nonumber      ,
\end{IEEEeqnarray}
%
and hence,
%
\begin{IEEEeqnarray}{rCl}
 \frac{dM_{\pt}}{d\pt} & = & - M_{\pt} \lfmat{\pt} = - \lfmat{\pt} M_{\pt} \label{app-eq:derivative_of_M}     ,
\end{IEEEeqnarray}
%
\emph{only} if $P_{\pt}$ and $\lfmat{\pt}$ commute. Pre-multiplying \eqref{app-eq:deterministic_lG_ODE} by $M_{\pt}$ and using \eqref{app-eq:derivative_of_M},
%
\begin{IEEEeqnarray}{rCl}
 M_{\pt} \frac{d\ls{\pt}}{d\pt} & = & M_{\pt} \lfmat{\pt} \ls{\pt} + M_{\pt} \lfshift{\pt} \nonumber \\
 \frac{d}{d\pt}\left[ M_{\pt} \ls{\pt} \right] & = & M_{\pt} \lfshift{\pt} \nonumber     .
\end{IEEEeqnarray}
%
Finally, integrating leads to,
%
\begin{IEEEeqnarray}{rCl}
 \ls{\pt} & = & M_{\pt}^{-1} \left[ C + \int_{\pt_0}^{\pt} M_{l} \lfshift{l} dl \right]      .
\end{IEEEeqnarray}

For the optimal deterministic linear Gaussian flow,
%
\begin{IEEEeqnarray}{rCl}
 \lfmat{\pt} & = & - \frac{1}{2} \transcov \obsmat^T \left(\obscov + \pt \obsmat \transcov \obsmat^T \right)^{-1} \obsmat \nonumber     .
\end{IEEEeqnarray}
%
Hence,
%
\begin{IEEEeqnarray}{rCl}
 P_{\pt}  & = & - \int_{\pt_0}^{\pt_1} \lfmat{l} dl \nonumber \\
          & = & \frac{1}{2} \log\left( I + \pt \transcov \obsmat^T \obscov^{-1} \obsmat \right) \nonumber \\
 M_{\pt}  & = & \exp\left\{ P_{\pt} \right\} \nonumber \\
          & = & \left( I + \pt \transcov \obsmat^T \obscov^{-1} \obsmat \right)^{\frac{1}{2}} \nonumber     ,
\end{IEEEeqnarray}
%
in which the integral has been solved using the matrix logarithm. It is simple to check that $P_{\pt}$ and $\lfmat{\pt}$ fulfill the requirement that they commute. It will be helpful to define the following intermediate variables,
%
\begin{IEEEeqnarray}{rCl}
 X               & = & \transcov \obsmat^T \obscov^{-1} \obsmat \nonumber \\
 \lginterm{\pt} & = & \left(I + \pt X\right) \nonumber     ,
\end{IEEEeqnarray}
%
which means that,
%
\begin{IEEEeqnarray}{rCl}
 \lginterm{\pt} & = & \left(I + \pt X\right) \nonumber \\
 \lgoicov{\pt}  & = & \lginterm{\pt}^{-1} \transcov \nonumber \\
 M_{\pt}        & = & \lginterm{\pt}^{\frac{1}{2}} \nonumber \\
 \lfmat{\pt}    & = & - \frac{1}{2} \lginterm{\pt}^{-1} \transcov \obsmat^T \obscov^{-1} \obsmat \nonumber \\
                & = & - \frac{1}{2} \lginterm{\pt}^{-1} X \nonumber \\
\end{IEEEeqnarray}
%
Also, observe that,
%
\begin{IEEEeqnarray}{rCl}
 \lfmat{\pt}^T & = & \transcov^{-1} \lfmat{\pt} \transcov \nonumber \\
 \transcov \obsmat^T \obscov^{-1} \ob{\pt} & = & X \obsmat^+ \ob{\pt} \nonumber     ,
\end{IEEEeqnarray}
%
where $^+$ indicates the Moore-Penrose pseudo-inverse. This final identity is true for full rank $\obsmat$ of any dimensions (see appendix \ref{app:pseudoinverse_proofs}).

Now, to solve the integral, start with \eqref{app-eq:lG_shift_basic}, the equation for $\lfshift{\pt}$,
%
\begin{IEEEeqnarray}{rCl}
 \lfshift{\pt} & = & \lgoicov{\pt} \left[ \obsmat^T \obscov^{-1} \ob{\rt} + \lfmat{\pt}^T \lgoicov{\pt}^{-1} \lgoimean{\pt} \right] \nonumber \\
               & = & \lginterm{\pt}^{-1} \transcov \left[ \obsmat^T \obscov^{-1} \ob{\rt} + \transcov^{-1} \lfmat{\pt} \transcov \left( \transcov^{-1} \transmean + \pt \obsmat^T \obscov^{-1} \ob{\rt} \right) \right] \nonumber \\
               & = & \lginterm{\pt}^{-1} \left[ \transcov \obsmat^T \obscov^{-1} \ob{\rt} - \frac{1}{2} \lginterm{\pt}^{-1} X \left( \transmean + \pt \transcov \obsmat^T \obscov^{-1} \ob{\rt} \right) \right] \nonumber \\
               & = & \lginterm{\pt}^{-2} \left[ \left(I + \pt X\right) X \obsmat^+ \ob{\rt} - \frac{1}{2} X \left(\transmean + \pt X \obsmat^+ \ob{\rt} \right) \right] \nonumber \\
               & = & \frac{1}{2} \lginterm{\pt}^{-2} \left[ 2 X \obsmat^+ \ob{\rt} + 2 \pt X^2 \obsmat^+ \ob{\rt} - X \transmean - \pt X^2 \obsmat^+ \ob{\rt} \right] \nonumber \\
               & = & \frac{1}{2} \lginterm{\pt}^{-2} \left[ \left(I + \pt X\right) X \obsmat^+ \ob{\rt} + X \left( \obsmat^+ \ob{\rt} - \transmean \right) \right] \nonumber \\
               & = & \frac{1}{2} \lginterm{\pt}^{-1} \left[ X \obsmat^+ \ob{\rt} + \lginterm{\pt}^{-1} X \left( \obsmat^+ \ob{\rt} - \transmean \right) \right] .
\end{IEEEeqnarray}

This leads us to the following solution to the integral,
%
\begin{IEEEeqnarray}{rCl}
 \int_{\pt_0}^{\pt} M_{l} \lfshift{l} dl & = & \frac{1}{2} \int_{\pt_0}^{\pt} \lginterm{l}^{-\frac{1}{2}} \left[ X \obsmat^+ \ob{\rt} + \lginterm{l}^{-1} X \left( \obsmat^+ \ob{\rt} - \transmean \right) \right] dl \nonumber \\
 & = & \frac{1}{2} \int_{\pt_0}^{\pt} \left(I + l X\right)^{-\frac{1}{2}} X dl \obsmat^+ \ob{\rt} + \frac{1}{2} \int_{\pt_0}^{\pt} \left(I + l X\right)^{-\frac{3}{2}} X dl \left( \obsmat^+ \ob{\rt} - \transmean \right) \nonumber \\
 & = & \frac{1}{2} \left[ 2 \left(I + l X\right)^{\frac{1}{2}} \right]_{\pt_0}^{\pt} \obsmat^+ \ob{\rt} + \frac{1}{2} \left[ -2 \left(I + l X\right)^{-\frac{1}{2}} \right]_{\pt_0}^{\pt} \left( \obsmat^+ \ob{\rt} - \transmean \right) \nonumber \\
 & = & \left[ \lginterm{\pt}^{\frac{1}{2}} - \lginterm{\pt_0}^{\frac{1}{2}} \right] \obsmat^+ \ob{\rt} - \left[ \lginterm{\pt}^{-\frac{1}{2}} - \lginterm{\pt_0}^{-\frac{1}{2}} \right] \left( \obsmat^+ \ob{\rt} - \transmean \right)      .
\end{IEEEeqnarray}

The optimal map is given by,
%
\begin{IEEEeqnarray}{rCl}
 \ls{\pt} & = & M_{\pt}^{-1} \left[ C + \int_{\pt_0}^{\pt} M_{l} \lfshift{l} dl \right] \nonumber \\
 & = & \lginterm{\pt}^{-\frac{1}{2}} \left\{ C + \left[ \lginterm{\pt}^{\frac{1}{2}} - \lginterm{\pt_0}^{\frac{1}{2}} \right] \obsmat^+ \ob{\rt} - \left[ \lginterm{\pt}^{-\frac{1}{2}} - \lginterm{\pt_0}^{-\frac{1}{2}} \right] \left( \obsmat^+ \ob{\rt} - \transmean \right) \right\}     .
\end{IEEEeqnarray}

The initial conditions allow us to find the constant of integration, $C$,
%
\begin{IEEEeqnarray}{rCl}
  \ls{\pt_0} & = & \lginterm{\pt_0}^{-\frac{1}{2}} C     .
\end{IEEEeqnarray}

Finally,
%
\begin{IEEEeqnarray}{rCl}
 \ls{\pt} & = & \lginterm{\pt}^{-\frac{1}{2}} \left\{ \lginterm{\pt_0}^{\frac{1}{2}} \ls{\pt_0} + \left[ \lginterm{\pt}^{\frac{1}{2}} - \lginterm{\pt_0}^{\frac{1}{2}} \right] \obsmat^+ \ob{\rt} - \left[ \lginterm{\pt}^{-\frac{1}{2}} - \lginterm{\pt_0}^{-\frac{1}{2}} \right] \left( \obsmat^+ \ob{\rt} - \transmean \right) \right\}     .
\end{IEEEeqnarray}


\section{Optimal Importance Density for a Linear Gaussian Model} \label{app:optimal_importance_density_linear_Gaussian}

When $\flowdiffuse{\pt} \ne 0$, the particle flow is governed by,
%
\begin{IEEEeqnarray}{rCl}
 d\ls{\pt} & = & \flowdrift{\pt}(\ls{\pt}) d\pt + \flowdiffuse{\pt} d\flowbm{\pt} \nonumber \\
           & = & \left[ \lfmat{D,\pt} \ls{\pt} + \lfshift{D,\pt} \right] d\pt + \flowdiffuse{\pt} d\flowbm{\pt}  \label{app-eq:stochastic_lG_SDE}     .
\end{IEEEeqnarray}

If a particle if moved from a known position according to this stochastic differential equation from pseudo-time $\pt_0$ to $\pt_1$, then the resulting perturbation is equivalent to sampling from an importance density, $\impden(\ls{\pt_1} | \ls{\pt_0})$, which can be calculated analytically from the optimal flow derived for the linear Gaussian flow. As in appendix~\ref{app:optimal_map_linear_Gaussian} the solution is obtained through a matrix form of the integrating factor method. First define,
%
\begin{IEEEeqnarray}{rCl}
 P_{\pt} & = & - \int_{\pt_0}^{\pt_1} \lfmat{D,l} dl \nonumber \\
 M_{\pt} & = & \exp\left\{ P_{\pt} \right\} \nonumber      ,
\end{IEEEeqnarray}
%
and hence,
%
\begin{IEEEeqnarray}{rCl}
 dM_{\pt} & = & - M_{\pt} \lfmat{\pt} d\pt = - \lfmat{\pt} M_{\pt} d\pt \label{app-eq:differential_of_M}     ,
\end{IEEEeqnarray}
%
\emph{only} if $P_{\pt}$ and $\lfmat{\pt}$ commute. Pre-multiplying \eqref{app-eq:stochastic_lG_SDE} by $M_{\pt}$ and using \eqref{app-eq:differential_of_M},
%
\begin{IEEEeqnarray}{rCl}
 M_{\pt} d\ls{\pt} & = & M_{\pt} \lfmat{D,\pt} \ls{\pt} d\pt + M_{\pt} \lfshift{D,\pt} d\pt + M_{\pt} \flowdiffuse{\pt} d\flowbm{\pt} \nonumber \\
 d\left( M_{\pt} \ls{\pt} \right) & = & M_{\pt} \lfshift{D,\pt} d\pt + M_{\pt} \flowdiffuse{\pt} d\flowbm{\pt} \nonumber     .
\end{IEEEeqnarray}
%
Finally, integrating leads to,
%
\begin{IEEEeqnarray}{rCl}
 \ls{\pt} & = & M_{\pt}^{-1} \left[ C + \int_{\pt_0}^{\pt} M_{l} \lfshift{l} dl + \int_{\pt_0}^{\pt} M_{l} \flowdiffuse{l} d\flowbm{l} \right]      .
\end{IEEEeqnarray}

An intuitive form for $\flowdiffuse{\pt}$, which also leads to an analytic solution is as follows,
%
\begin{IEEEeqnarray}{rCl}
 \flowdiffuse{\pt} & = & \left[ \lfdiffsf \lgoicov{\pt} \right]^{\frac{1}{2}} \nonumber \\
 & = & \left[ \lfdiffsf \left( \transcov^{-1} + \pt \obsmat^T \obscov^{-1} \obsmat \right) \right]^{\frac{1}{2}}     ,
\end{IEEEeqnarray}
%
which gives us,
%
\begin{IEEEeqnarray}{rCl}
 \flowcov{\pt} & = & \frac{1}{2} \flowdiffuse{\pt} \flowdiffuse{\pt}^T \nonumber \\
               & = & \frac{1}{2} \lfdiffsf \lgoicov{\pt}     .
\end{IEEEeqnarray}

In the following, we use the intermediate terms and results defined and derived in appendix~\ref{app:optimal_map_linear_Gaussian}. For the optimal stochastic linear Gaussian flow,
%
\begin{IEEEeqnarray}{rCl}
 \lfmat{D,\pt} & = & \lfmat{\pt} - \flowcov{\pt} \lgoicov{\pt}^{-1} \nonumber     .
\end{IEEEeqnarray}
%
Hence,
%
\begin{IEEEeqnarray}{rCl}
 P_{\pt} & = & \frac{1}{2}\log\left( I + \pt \transcov \obsmat^T \obscov^{-1} \obsmat \right) + \frac{1}{2} \lfdiffsf \pt I \nonumber \\
 M_{\pt} & = & \exp\left\{ \frac{1}{2} \lfdiffsf \pt \right\} \left( I + \pt \transcov \obsmat^T \obscov^{-1} \obsmat \right)^{\frac{1}{2}} \nonumber \\
         & = & \exp\left\{ \frac{1}{2} \lfdiffsf \pt \right\} \lginterm{\pt}^{\frac{1}{2}}     .
\end{IEEEeqnarray}
%
As before, it is simple to check that $P_{\pt}$ and $\lfmat{\pt}$ fulfill the requirement that they commute.

Now, to solve the first integral, start with \eqref{app-eq:lg_shift_stochastic}, the equation for $\lfshift{D,\pt}$,
%
\begin{IEEEeqnarray}{rCl}
 \lfshift{D,\pt} & = & \lfshift{\pt} + \flowcov{\pt} \left[ \transcov^{-1} \transmean + \pt \obsmat^T \obscov^{-1} \ob{\rt} \right] \nonumber \\
                 & = & \frac{1}{2} \lginterm{\pt}^{-1} \left[ X \obsmat^+ \ob{\rt} + \lginterm{\pt}^{-1} X \left( \obsmat^+ \ob{\rt} - \transmean \right) \right] + \frac{1}{2} \lfdiffsf \left( \transcov^{-1} + \pt \obsmat^T \obscov^{-1} \obsmat \right)^{-1} \left[ \transcov^{-1} \transmean + \pt \obsmat^T \obscov^{-1} \ob{\rt} \right] \nonumber \\
                 & = & \frac{1}{2} \lginterm{\pt}^{-1} \left[ X \obsmat^+ \ob{\rt} + \lginterm{\pt}^{-1} X \left( \obsmat^+ \ob{\rt} - \transmean \right) \right] + \frac{1}{2} \lfdiffsf \lginterm{\pt}^{-1} \left[ \transmean + \pt X \obsmat^+ \ob{\rt} \right] \nonumber \\
                 & = & \frac{1}{2} \lginterm{\pt}^{-1} \left[ X \obsmat^+ \ob{\rt} + \lginterm{\pt}^{-1} X \left( \obsmat^+ \ob{\rt} - \transmean \right) + \lfdiffsf \transmean + \lfdiffsf \pt X \obsmat^+ \ob{\rt} \right] \nonumber \\
                 & = & \frac{1}{2} \lginterm{\pt}^{-1} \left[ X \obsmat^+ \ob{\rt} + \lginterm{\pt}^{-1} X \left( \obsmat^+ \ob{\rt} - \transmean \right) + \lfdiffsf \transmean + \lfdiffsf \pt \left( \lginterm{\pt} - I \right) \obsmat^+ \ob{\rt} \right] \nonumber \\
                 & = & \frac{1}{2} \lginterm{\pt}^{-1} \left[ \left(X + \lfdiffsf \lginterm{\pt} \right) \obsmat^+ \ob{\rt} - \left( \lfdiffsf I - \lginterm{\pt}^{-1} X \right) \left( \obsmat^+ \ob{\rt} - \transmean \right) \right]     .
\end{IEEEeqnarray}

This leads us to the following solution to the integral,
%
\begin{IEEEeqnarray}{rCl}
 \int_{\pt_0}^{\pt} M_{l} \lfshift{D,l} dl & = & \frac{1}{2} \int_{\pt_0}^{\pt} \exp\left\{ \frac{1}{2} \lfdiffsf l \right\} \lginterm{l}^{-\frac{1}{2}} \left[ \left(X + \lfdiffsf \lginterm{l} \right) \obsmat^+ \ob{\rt} - \left( \lfdiffsf I - \lginterm{l}^{-1} X \right) \left( \obsmat^+ \ob{\rt} - \transmean \right) \right] dl \nonumber \\
 & = & \int_{\pt_0}^{\pt} \frac{1}{2} \exp\left\{ \frac{1}{2} \lfdiffsf l \right\} \lginterm{l}^{-\frac{1}{2}} \left(X + \lfdiffsf \lginterm{l} \right) dl \obsmat^+ \ob{\rt} \nonumber \\
 & & - \: \int_{\pt_0}^{\pt} \frac{1}{2} \exp\left\{ \frac{1}{2} \lfdiffsf l \right\} \lginterm{l}^{-\frac{1}{2}} \left( \lfdiffsf I - \lginterm{l}^{-1} X \right) dl \left( \obsmat^+ \ob{\rt} - \transmean \right) \nonumber \\
 & = & \left[ \exp\left\{ \frac{1}{2} \lfdiffsf l \right\} \lginterm{l}^{\frac{1}{2}} \right]_{\pt_0}^{\pt} \obsmat^+ \ob{\rt} \nonumber \\
 & & - \: \left[ \exp\left\{ \frac{1}{2} \lfdiffsf l \right\} \lginterm{l}^{-\frac{1}{2}} \right]_{\pt_0}^{\pt} \left( \obsmat^+ \ob{\rt} - \transmean \right) \nonumber \\
 & = & \left[ \exp\left\{ \frac{1}{2} \lfdiffsf \pt \right\} \lginterm{\pt}^{\frac{1}{2}} - \exp\left\{ \frac{1}{2} \lfdiffsf \pt_0 \right\} \lginterm{\pt_0}^{\frac{1}{2}} \right] \obsmat^+ \ob{\rt} \nonumber \\
 & & - \: \left[ \exp\left\{ \frac{1}{2} \lfdiffsf \pt \right\} \lginterm{\pt}^{-\frac{1}{2}} - \exp\left\{ \frac{1}{2} \lfdiffsf \pt_0 \right\} \lginterm{\pt_0}^{-\frac{1}{2}} \right] \left( \obsmat^+ \ob{\rt} - \transmean \right)      .
\end{IEEEeqnarray}
%
Hence, the deterministic term is given by,
%
\begin{IEEEeqnarray}{rCl}
 M_{\pt}^{-1} \left[ C + \int_{\pt_0}^{\pt} M_{l} \lfshift{l} dl \right] & = & \exp\left\{ -\frac{1}{2} \lfdiffsf \pt \right\} \lginterm{\pt}^{-\frac{1}{2}} \bigg\{ \lginterm{\pt_0}^{\frac{1}{2}} \ls{\pt_0} \nonumber \\
 & & + \: \left[ \exp\left\{ \frac{1}{2} \lfdiffsf \pt \right\} \lginterm{\pt}^{\frac{1}{2}} - \exp\left\{ \frac{1}{2} \lfdiffsf \pt_0 \right\} \lginterm{\pt_0}^{\frac{1}{2}} \right] \obsmat^+ \ob{\rt} \nonumber \\
 & & - \: \left[ \exp\left\{ \frac{1}{2} \lfdiffsf \pt \right\} \lginterm{\pt}^{-\frac{1}{2}} - \exp\left\{ \frac{1}{2} \lfdiffsf \pt_0 \right\} \lginterm{\pt_0}^{-\frac{1}{2}} \right] \left( \obsmat^+ \ob{\rt} - \transmean \right) \bigg\}      .
\end{IEEEeqnarray}

Next, consider the stochastic integral,
%
\begin{IEEEeqnarray}{rCl}
 \int_{\pt_0}^{\pt} M_{l} \flowdiffuse{l} d\flowbm{l} & = & \int_{\pt_0}^{\pt} \exp\left\{ \frac{1}{2} \lfdiffsf l \right\} \lginterm{l}^{\frac{1}{2}} \left[ \lfdiffsf \lginterm{l}^{-1} \transcov \right]^{\frac{1}{2}} d\flowbm{l} \nonumber \\
 & = & \lfdiffsf^{\frac{1}{2}} \int_{\pt_0}^{\pt} \exp\left\{ \frac{1}{2} \lfdiffsf l \right\} \transcov^{\frac{1}{2}} d\flowbm{l}      .
\end{IEEEeqnarray}

Using Ito's Lemma, this will be normally distributed random variable with zero mean and variance,
%
\begin{IEEEeqnarray}{rCl}
 \variance{}\left[ \int_{\pt_0}^{\pt} M_{l} \flowdiffuse{l} d\flowbm{l} \right] & = & \expect{}\left[ \left(\int_{\pt_0}^{\pt} M_{l} \flowdiffuse{l} d\flowbm{l}\right) \left(\int_{\pt_0}^{\pt} M_{l'} \flowdiffuse{l'} d\flowbm{l'}\right)^T \right] \nonumber \\
 & = & \lfdiffsf \expect{}\left[ \int_{\pt_0}^{\pt} \exp\left\{ \frac{1}{2} \lfdiffsf l \right\} \transcov^{\frac{1}{2}} d\flowbm{l} \int_{\pt_0}^{\pt} \exp\left\{ \frac{1}{2} \lfdiffsf l' \right\} \transcov^{\frac{1}{2}} d\flowbm{l'}^T \right] \nonumber \\
 & = & \lfdiffsf \int_{\pt_0}^{\pt} \int_{\pt_0}^{\pt} \exp\left\{ \frac{1}{2} \lfdiffsf l \right\} \exp\left\{ \frac{1}{2} \lfdiffsf l' \right\}\transcov
 \underbrace{\expect{}\left[ d\flowbm{l} d\flowbm{l'}^T \right]}_{=\delta(l'=l)dl} \nonumber \\
 & = & \lfdiffsf \int_{\pt_0}^{\pt} \exp\left\{ \lfdiffsf l \right\} \transcov dl \nonumber \\
 & = & \left[ \exp\left\{ \lfdiffsf \pt \right\} - \exp\left\{ \lfdiffsf \pt_0 \right\} \right] \transcov     .
\end{IEEEeqnarray}

Thus, the stochastic term in the solution is also a normally distributed random variable with zero mean and variance,
%
\begin{IEEEeqnarray}{rCl}
 \variance{}\left[ M_{\pt}^{-1} \int_{\pt_0}^{\pt} M_{l} \flowdiffuse{l} d\flowbm{l} \right] & = & \left( \exp\left\{ -\frac{1}{2} \lfdiffsf \pt \right\} \lginterm{\pt}^{-\frac{1}{2}} \right) \left[ \exp\left\{ \lfdiffsf \pt \right\} - \exp\left\{ \lfdiffsf \pt_0 \right\} \right] \transcov \left( \exp\left\{ -\frac{1}{2} \lfdiffsf \pt \right\} \lginterm{\pt}^{-\frac{1}{2}} \right)^T \nonumber \\
 & = & \left[ 1 - \exp\left\{ - \lfdiffsf \left(\pt - \pt_0\right) \right\} \right] \lginterm{\pt}^{-\frac{1}{2}} \transcov \transcov^T \lginterm{\pt}^{-\frac{1}{2}T} \nonumber \\
 & = & \left[ 1 - \exp\left\{ - \lfdiffsf \left(\pt - \pt_0\right) \right\} \right] \left(\transcov^{-1} + \pt \obsmat^T \obscov^{-1} \obsmat\right)^{-1} \nonumber \\
 & = & \left[ 1 - \exp\left\{ - \lfdiffsf \left(\pt - \pt_0\right) \right\} \right] \lgoicov{\pt}     .
\end{IEEEeqnarray}

Putting all this together gives us a proposal density corresponding to optimal stochastic flow for a linear Gaussian model,
%
\begin{IEEEeqnarray}{rCl}
 \impden(\ls{\pt_1} | \ls{\pt_0}) & = & \normal{\ls{\pt_1}}{\Gamma \ls{\pt_0} + \nu}{\Omega} \\
 \Gamma & = & \exp\left\{ -\frac{1}{2} \lfdiffsf \pt_1 \right\} \lginterm{\pt_1}^{-\frac{1}{2}} \lginterm{\pt_0} \nonumber \\
 \nu    & = & \exp\left\{ -\frac{1}{2} \lfdiffsf \pt_1 \right\} \lginterm{\pt_1}^{-\frac{1}{2}} \Bigg\{ \left[ \exp\left\{ \frac{1}{2} \lfdiffsf \pt_1 \right\} \lginterm{\pt_1}^{\frac{1}{2}} - \exp\left\{ \frac{1}{2} \lfdiffsf \pt_0 \right\} \lginterm{\pt_0}^{\frac{1}{2}} \right] \obsmat^+ \ob{\rt} \nonumber \\
 & & - \: \left[ \exp\left\{ \frac{1}{2} \lfdiffsf \pt_1 \right\} \lginterm{\pt_1}^{-\frac{1}{2}} - \exp\left\{ \frac{1}{2} \lfdiffsf \pt_0 \right\} \lginterm{\pt_0}^{-\frac{1}{2}} \right] \left( \obsmat^+ \ob{\rt} - \transmean \right) \Bigg\} \nonumber \\
 \Omega & = & \left[ 1 - \exp\left\{ - \lfdiffsf \left(\pt_1 - \pt_0\right) \right\} \right] \lgoicov{\pt_1}
\end{IEEEeqnarray}












\section{Matrix Functions}

\subsection{Logarithms}

The matrix log is defined via its Taylor series,
%
\begin{IEEEeqnarray}{rCl}
 \log\left(I+X\right) & = & X - \frac{1}{2} X^2 + \frac{1}{3} X^3 - \dots + (-1)^{n+1} \frac{1}{n} X^n + \dots     .
\end{IEEEeqnarray}

Thus, by diagonalising $X$ we have,
%
\begin{IEEEeqnarray}{rCl}
 X         & = & U \Lambda U^{-1} \nonumber \\
 \log\left(I+X\right) & = & U \log\left(I+\Lambda\right) U^{-1} \nonumber     ,
\end{IEEEeqnarray}
%
where, for positive definite $X$, the log of the diagonal matrix is calculated by simply taking the log of the diagonal terms.

By diagonalisation, we can show that the matrix log solves the following integrals,
%
\begin{IEEEeqnarray}{rCl}
 \int_{\pt_0}^{\pt_1} \left( I + l X \right)^{-1} X dl & = & \left[ \left(I + \pt_1 X\right) \right]_{\pt_0}^{\pt_1} \nonumber \\
 \int_{\pt_0}^{\pt_1} X \left( I + l X \right)^{-1} dl & = & \left[ \left(I + \pt_1 X\right) \right]_{\pt_0}^{\pt_1} \nonumber      .
\end{IEEEeqnarray}

The matrix log follows most of the same rules as the scalar log, in particular,
%
\begin{IEEEeqnarray}{rCl}
 a \log\left(X\right) & = & \log\left(X^a\right) \nonumber     .
\end{IEEEeqnarray}

\subsection{Roots}

The following matrix root integral ($n \ne 0$) may be proven by Taylor series or diagonalisation,
%
\begin{IEEEeqnarray}{rCl}
 \int_{\pt_0}^{\pt_1} \left( I + l X \right)^{n} X dl & = & \frac{1}{n+1} \left[ \left( I + \pt X \right)^{n+1} \right]_{\pt_0}^{\pt_1} \nonumber       .
\end{IEEEeqnarray}

\subsection{Things that Commute}

I commute. About $4 \frac{1}{2}$ miles by bicycle.  \\

\noindent These are all provable using the Taylor series,
%
\begin{IEEEeqnarray}{rCl}
 X \left( I + \pt X \right)^{-1} & = & \left( I + \pt X \right)^{-1} X \nonumber \\
 X \log\left( I + \pt X \right) & = & \log\left( I + \pt X \right) X \nonumber \\
 \left( I + \pt X \right)^{-1} \log\left( I + \pt X \right) & = & \log\left( I + \pt X \right) \left( I + \pt X \right)^{-1} \nonumber     .
\end{IEEEeqnarray}



\section{Pseudo-Inverses} \label{app:pseudoinverse_proofs}

It is useful to show that if,
%
\begin{IEEEeqnarray}{rCl}
 X & = & \transcov \obsmat^T \obscov^{-1} \obsmat \nonumber     ,
\end{IEEEeqnarray}
%
then
%
\begin{IEEEeqnarray}{rCl}
 \transcov \obsmat^T \obscov^{-1} \ob{\pt} & = & X \obsmat^+ \ob{\pt} \nonumber     .
\end{IEEEeqnarray}

First consider the case when $\obsmat$ is square and full rank. This means that $\obsmat^+ = \obsmat^{-1}$, and the proof is trivial. Next consider the case when $\obsmat$ is fat (i.e. more columns than rows) and full rank. This means,
%
\begin{IEEEeqnarray}{rCl}
 \obsmat^+ & = & \obsmat^T \left(\obsmat \obsmat^T\right)^{-1} \nonumber \\
 \obsmat \obsmat^+ & = & I     ,
\end{IEEEeqnarray}
%
and again the proof is trivial.

Finally, consider the case when $\obsmat$ is wide (i.e. more rows than columns) and full rank, and $\obscov$ is also full rank. In this case,
%
\begin{IEEEeqnarray}{rCl}
 \left(\obsmat^T \obscov^{-1} \obsmat^T\right) \left(\obsmat^T \obscov^{-1} \obsmat^T\right)^{-1} & = & I     .
\end{IEEEeqnarray}
%
Hence,
%
\begin{IEEEeqnarray}{rCl}
 \transcov \obsmat^T \obscov^{-1} \ob{\pt} & = & \transcov \left(\obsmat^T \obscov^{-1} \obsmat^T\right) \left(\obsmat^T \obscov^{-1} \obsmat^T\right)^{-1} \obsmat^T \obscov^{-1} \ob{\pt} \nonumber \\
 & = & X \left(\obsmat^T \obscov^{-1} \obsmat^T\right)^{-1} \obsmat^T \obscov^{-1} \ob{\pt} \nonumber \\
 & = & X H^+ \ob{\pt} \nonumber     .
\end{IEEEeqnarray}
%
In the last line, we have used the pseudo-inverse expressions,
%
\begin{IEEEeqnarray}{rCl}
 \obsmat^+ & = & \left(\obsmat^T \obsmat\right)^{-1} \obsmat^T \nonumber \\
           & = & \left(\obsmat^T \obscov^{-1} \obsmat\right)^{-1} \obsmat^T \obscov^{-1} \nonumber \\
 \obsmat^+ \obsmat & = & I     .
\end{IEEEeqnarray}
%
The second expression for $\obsmat^+$ may be proven using a singular value decomposition on $\obsmat$.

{\meta Would be nice to generalise this for non-full rank $\obsmat$ and $\obscov$.}

\bibliographystyle{plain}
\bibliography{D:/pb404/Dropbox/PhD/OTbib}
%\bibliography{/home/pete/Dropbox/PhD/OTbib.bib}

\end{document}
